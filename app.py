import streamlit as st
import google.generativeai as genai
import os
import json
import re
import urllib.parse
import time
import random
import requests
from io import BytesIO
from PIL import Image

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI MV Director (Zombie Mode)", layout="wide")

# --- ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .scene-box {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 20px;
        border-left: 6px solid #4285F4;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .status-ok { color: green; font-weight: bold; }
    .status-err { color: red; font-weight: bold; }
    .status-warn { color: orange; font-weight: bold; }
    .diagnostic-log {
        font-family: monospace;
        font-size: 0.8em;
        max_height: 200px;
        overflow-y: auto;
        background-color: #f8f9fa;
        padding: 10px;
        border: 1px solid #ddd;
    }
</style>
""", unsafe_allow_html=True)

# --- API í‚¤ ë¡œë“œ ---
def get_api_key(key_name):
    if key_name in st.secrets:
        return st.secrets[key_name]
    elif os.getenv(key_name):
        return os.getenv(key_name)
    return None

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    gemini_key = get_api_key("GOOGLE_API_KEY")
    if gemini_key:
        st.success("âœ… Gemini Key ì—°ê²°ë¨")
    else:
        gemini_key = st.text_input("Google Gemini API Key", type="password")
    
    st.markdown("---")
    
    # [í•µì‹¬] ëŒ€ê·œëª¨ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (Zombie List)
    st.subheader("ğŸ¥ ì‹œìŠ¤í…œ ìƒì¡´ ì§„ë‹¨")
    
    # ì•Œë ¤ì§„ ëª¨ë“  Gemini ëª¨ë¸ ì‹ë³„ì (ìˆœì„œ: ìµœì‹  -> êµ¬í˜•)
    all_known_models = [
        # 2.0 Series (Newest)
        "gemini-2.0-flash-lite-preview-02-05",
        "gemini-2.0-flash-exp",
        
        # 1.5 Flash Series (Fast & Cheap)
        "gemini-1.5-flash",
        "gemini-1.5-flash-latest",
        "gemini-1.5-flash-001",
        "gemini-1.5-flash-002",
        "gemini-1.5-flash-8b",
        
        # 1.5 Pro Series (High Quality)
        "gemini-1.5-pro",
        "gemini-1.5-pro-latest",
        "gemini-1.5-pro-001",
        "gemini-1.5-pro-002",
        
        # Experimental (Randomly available)
        "gemini-exp-1206",
        "gemini-exp-1121",
        "learnlm-1.5-pro-experimental",
        
        # 1.0 Legacy (Last Resort)
        "gemini-1.0-pro",
        "gemini-1.0-pro-latest",
        "gemini-pro"
    ]
    
    # ì„¸ì…˜ì— 'ì‚´ì•„ìˆëŠ” ëª¨ë¸' ì €ì¥
    if 'alive_models' not in st.session_state:
        st.session_state['alive_models'] = []

    if st.button("ğŸ§¬ ì „ì²´ ëª¨ë¸ ì •ë°€ ìŠ¤ìº”"):
        if not gemini_key:
            st.error("API Key í•„ìš”")
        else:
            genai.configure(api_key=gemini_key)
            alive_list = []
            
            with st.status("ğŸ” ëª¨ë¸ ìƒì¡´ ì—¬ë¶€ í™•ì¸ ì¤‘...", expanded=True) as status:
                st.write("ê° ëª¨ë¸ì— 'Hi'ë¥¼ ë³´ë‚´ ì‘ë‹µì„ í™•ì¸í•©ë‹ˆë‹¤.")
                
                for m in all_known_models:
                    try:
                        # ìµœì†Œ í† í°ìœ¼ë¡œ í•‘(Ping) í…ŒìŠ¤íŠ¸
                        model = genai.GenerativeModel(m)
                        model.generate_content("Hi", generation_config={"max_output_tokens": 1})
                        
                        st.markdown(f"âœ… **{m}**: <span class='status-ok'>ìƒì¡´ (Alive)</span>", unsafe_allow_html=True)
                        alive_list.append(m)
                        
                    except Exception as e:
                        err_msg = str(e)
                        if "429" in err_msg or "Quota" in err_msg:
                            st.markdown(f"âš ï¸ **{m}**: <span class='status-warn'>í•œë„ ì´ˆê³¼ (429)</span>", unsafe_allow_html=True)
                        elif "404" in err_msg or "Not Found" in err_msg:
                            # 404ëŠ” ë„ˆë¬´ ë§ìœ¼ë¯€ë¡œ ë¡œê·¸ ê°„ì†Œí™”
                            # st.markdown(f"âŒ **{m}**: <span class='status-err'>ì—†ìŒ (404)</span>", unsafe_allow_html=True)
                            pass
                        else:
                            st.markdown(f"âŒ **{m}**: <span class='status-err'>ì‚¬ë§ ({err_msg[:20]}...)</span>", unsafe_allow_html=True)
                
                if alive_list:
                    st.session_state['alive_models'] = alive_list
                    status.update(label=f"ìŠ¤ìº” ì™„ë£Œ! ìƒì¡´ ëª¨ë¸ {len(alive_list)}ê°œ ë°œê²¬", state="complete")
                else:
                    status.update(label="ìŠ¤ìº” ì‹¤íŒ¨: ìƒì¡´ ëª¨ë¸ 0ê°œ", state="error")
                    st.error("ëª¨ë“  ëª¨ë¸ì´ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. API Keyë¥¼ ì ê²€í•˜ì„¸ìš”.")

    # ìŠ¤ìº” ê²°ê³¼ì— ë”°ë¼ ì„ íƒë°•ìŠ¤ ì—…ë°ì´íŠ¸
    final_model_list = st.session_state['alive_models'] if st.session_state['alive_models'] else all_known_models
    
    st.markdown("---")
    st.subheader("ğŸ¤– ë¶„ì„ ëª¨ë¸ ì„ íƒ")
    gemini_model = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸", 
        final_model_list, 
        index=0,
        help="ìŠ¤ìº”ì„ ëŒë¦¬ë©´ ì‚´ì•„ìˆëŠ” ëª¨ë¸ë§Œ í‘œì‹œë©ë‹ˆë‹¤."
    )
    
    st.markdown("---")
    st.subheader("ğŸ¨ ì´ë¯¸ì§€ ëª¨ë¸")
    image_model = st.selectbox("Pollinations ëª¨ë¸", ["flux", "turbo"], index=0)

    if st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

# --- ë©”ì¸ íƒ€ì´í‹€ ---
st.title("ğŸ¬ AI MV Director")
st.caption("Massive Model Scanner Mode | Zombie Fallback")

topic = st.text_area("ì˜ìƒ ì£¼ì œ ì…ë ¥", height=80, placeholder="ì˜ˆ: 2050ë…„ ì‚¬ì´ë²„í‘í¬ ì„œìš¸, ë¹„ ì˜¤ëŠ” ë°¤, ê³ ë…í•œ í˜•ì‚¬")

# ------------------------------------------------------------------
# 1. Gemini ë¡œì§ (ìƒì¡´ì ìš°ì„  íˆ¬ì…)
# ------------------------------------------------------------------

def clean_json_text(text):
    match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
    if match: return match.group(1)
    match = re.search(r"```\s*(.*?)\s*```", text, re.DOTALL)
    if match: return match.group(1)
    return text

def generate_with_fallback(prompt, api_key, start_model):
    genai.configure(api_key=api_key)
    
    # 1. ì‹œì‘ ëª¨ë¸ + ìŠ¤ìº”ëœ ìƒì¡´ ëª¨ë¸ë“¤ + ì „ì²´ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°)
    # ì „ëµ: ì‚¬ìš©ìê°€ ê³ ë¥¸ ë†ˆ -> ìŠ¤ìº”ìœ¼ë¡œ í™•ì¸ëœ ì‚° ë†ˆë“¤ -> ë‚˜ë¨¸ì§€ ì „ì²´
    
    fallback_chain = [start_model]
    
    # ì´ë¯¸ ì‚´ì•„ìˆë‹¤ê³  í™•ì¸ëœ ëª¨ë¸ë“¤ì„ ìš°ì„  ë°°ì¹˜ (ë§¤ìš° ì¤‘ìš”)
    if 'alive_models' in st.session_state and st.session_state['alive_models']:
        for m in st.session_state['alive_models']:
            if m not in fallback_chain:
                fallback_chain.append(m)
    
    # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ë‚˜ë¨¸ì§€ ë¦¬ìŠ¤íŠ¸ë„ ë’¤ì— ë¶™ì„ (ë³´í—˜)
    all_backups = [
        "gemini-1.5-flash", "gemini-1.5-flash-latest", "gemini-2.0-flash-lite-preview-02-05",
        "gemini-1.5-pro", "gemini-1.0-pro"
    ]
    for b in all_backups:
        if b not in fallback_chain:
            fallback_chain.append(b)
            
    last_error = None
    
    # 2. ìˆœì°¨ ì‹¤í–‰
    for model_name in fallback_chain:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            time.sleep(1) 
            return response.text, model_name 
            
        except Exception as e:
            last_error = e
            # ì‹¤íŒ¨ ì‹œ ë¹ ë¥´ê²Œ ìŠ¤í‚µ
            time.sleep(0.5)
            continue
            
    raise Exception(f"All models ({len(fallback_chain)} tried) failed. Last Error: {last_error}")

def generate_plan_gemini(topic, api_key, model_name):
    try:
        prompt = f"""
        You are a professional Music Video Director.
        Analyze the following theme: "{topic}"
        Create a detailed plan in JSON format ONLY.
        
        JSON Structure:
        {{
          "project_title": "Creative Title (Korean)",
          "logline": "One sentence concept (Korean)",
          "music": {{
            "style": "Genre and Mood (Korean)",
            "suno_prompt": "English prompt for music AI."
          }},
          "visual_style": {{
            "description": "Visual tone (Korean)",
            "character_prompt": "English description of the main character."
          }},
          "scenes": [
            {{
              "scene_num": 1,
              "timecode": "00:00-00:05",
              "action": "Scene description (Korean)",
              "camera": "Shot type (Korean)",
              "image_prompt": "Highly detailed English prompt for image generation."
            }}
            // Create 4 scenes total
          ]
        }}
        """
        response_text, used_model = generate_with_fallback(prompt, api_key, model_name)
        st.toast(f"âœ… ê¸°íš ì™„ë£Œ (Used: {used_model})")
        return json.loads(clean_json_text(response_text))
    except Exception as e:
        st.error(f"ê¸°íšì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# ------------------------------------------------------------------
# 2. ì´ë¯¸ì§€ ìƒì„± ë¡œì§
# ------------------------------------------------------------------

def fetch_image_server_side(prompt, model="flux"):
    safe_prompt = urllib.parse.quote(prompt[:400])
    seed = random.randint(0, 999999)
    url = f"https://image.pollinations.ai/prompt/{safe_prompt}?width=1024&height=576&model={model}&nologo=true&seed={seed}&enhance=false"
    
    try:
        response = requests.get(url, timeout=20)
        if response.status_code == 200:
            return Image.open(BytesIO(response.content))
    except:
        pass
    return None

# ------------------------------------------------------------------
# 3. ì‹¤í–‰ ë¡œì§
# ------------------------------------------------------------------

if 'plan_data' not in st.session_state:
    st.session_state['plan_data'] = None
if 'generated_images' not in st.session_state:
    st.session_state['generated_images'] = {} 

start_btn = st.button("ğŸš€ í”„ë¡œì íŠ¸ ì‹œì‘")

if start_btn:
    if not gemini_key or not topic:
        st.warning("API Keyì™€ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        st.session_state['generated_images'] = {} 
        st.session_state['plan_data'] = None
        
        with st.status("ğŸ“ ê¸°íšì•ˆ ì‘ì„± ì¤‘...", expanded=True) as status:
            st.session_state['plan_data'] = generate_plan_gemini(topic, gemini_key, gemini_model)
            
            if st.session_state['plan_data']:
                status.update(label="ê¸°íš ì™„ë£Œ!", state="complete", expanded=False)
            else:
                status.update(label="ì‹¤íŒ¨", state="error")

if st.session_state['plan_data']:
    plan = st.session_state['plan_data']
    
    st.divider()
    st.markdown(f"## ğŸ¥ {plan['project_title']}")
    st.info(f"**ë¡œê·¸ë¼ì¸:** {plan['logline']}")
    
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### ğŸµ Music")
        st.write(plan['music']['style'])
        st.code(plan['music']['suno_prompt'], language="text")
    with c2:
        st.markdown("### ğŸ¨ Visuals")
        st.write(plan['visual_style']['description'])
        st.code(plan['visual_style']['character_prompt'], language="text")
    
    st.markdown("---")
    st.subheader("ğŸ–¼ï¸ ë¹„ì£¼ì–¼ ìŠ¤í† ë¦¬ë³´ë“œ")

    for scene in plan['scenes']:
        scene_num = scene['scene_num']
        
        with st.container():
            st.markdown(f"<div class='scene-box'>", unsafe_allow_html=True)
            st.markdown(f"#### ğŸ¬ Scene {scene_num} <span style='font-size:0.8em; color:gray'>({scene['timecode']})</span>", unsafe_allow_html=True)
            
            col_text, col_img = st.columns([1, 1.5])
            
            with col_text:
                st.write(f"**ë‚´ìš©:** {scene['action']}")
                st.write(f"**ì´¬ì˜:** {scene['camera']}")
                with st.expander("í”„ë¡¬í”„íŠ¸ ìƒì„¸"):
                    st.code(scene['image_prompt'], language="text")
            
            with col_img:
                if scene_num in st.session_state['generated_images']:
                    st.image(st.session_state['generated_images'][scene_num], use_container_width=True)
                    st.success("âœ… ìƒì„± ì™„ë£Œ")
                
                else:
                    msg = st.empty()
                    msg.info("ğŸ“¸ ì´¬ì˜ ì¤‘...")
                    
                    full_prompt = f"{plan['visual_style']['character_prompt']}, {scene['image_prompt']}"
                    img_data = fetch_image_server_side(full_prompt, image_model)
                    
                    if img_data:
                        st.session_state['generated_images'][scene_num] = img_data
                        msg.empty()
                        st.rerun()
                    else:
                        msg.error("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")

            st.markdown("</div>", unsafe_allow_html=True)
    
    if len(st.session_state['generated_images']) == len(plan['scenes']):
        st.success("âœ¨ í”„ë¡œì íŠ¸ ì™„ì„±!")
