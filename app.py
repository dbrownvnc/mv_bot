import streamlit as st
import google.generativeai as genai
import os
import json
import re
import urllib.parse
import time
import random
import requests
from io import BytesIO
from PIL import Image
from datetime import datetime
import base64

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI MV Director Pro", layout="wide", initial_sidebar_state="collapsed")

# --- ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .block-container { padding-top: 1rem; padding-bottom: 5rem; }
    .scene-box {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 12px;
        padding: 15px;
        margin-bottom: 15px;
        border-left: 5px solid #4285F4;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .turntable-box {
        background-color: #fff9e6;
        border: 2px solid #FFD700;
        border-radius: 12px;
        padding: 15px;
        margin-bottom: 20px;
    }
    .youtube-box {
        background-color: #ffe6e6;
        border: 2px solid #FF0000;
        border-radius: 12px;
        padding: 20px;
        margin: 20px 0;
    }
    .trend-box {
        background-color: #e6f7ff;
        border: 2px solid #1890ff;
        border-radius: 12px;
        padding: 15px;
        margin: 10px 0;
    }
    .suno-section {
        background-color: #f5f0ff;
        border: 1px solid #722ed1;
        border-radius: 8px;
        padding: 12px;
        margin: 8px 0;
    }
    .turntable-tag {
        display: inline-block;
        background: linear-gradient(135deg, #FFD700, #FFA500);
        color: #000;
        padding: 4px 12px;
        border-radius: 15px;
        margin: 4px;
        font-size: 11px;
        font-weight: bold;
    }
    .stButton>button {
        width: 100%;
        border-radius: 8px;
        height: 3em; 
        font-weight: bold;
    }
    .status-box {
        background-color: #f0f7ff;
        border-left: 4px solid #4285F4;
        padding: 12px;
        border-radius: 8px;
        margin: 10px 0;
        font-size: 14px;
    }
    .realtime-calc {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 15px;
        border-radius: 10px;
        text-align: center;
        font-size: 18px;
        font-weight: bold;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# --- í™•ì¥ëœ íŠ¸ë Œë“œ í‚¤ì›Œë“œ (ëŒ€í­ í™•ì¥) ---
TRENDING_KEYWORDS = {
    "emotions": [
        "heartbreak", "hope", "nostalgia", "euphoria", "melancholy", "rage", "peace", "anxiety", "joy", "loneliness",
        "obsession", "liberation", "despair", "ecstasy", "bittersweet", "rebellion", "serenity", "madness", "yearning", "triumph",
        "betrayal", "redemption", "devotion", "confusion", "enlightenment", "paranoia", "bliss", "grief", "wonder", "defiance"
    ],
    "settings": [
        "neon city", "abandoned subway", "rooftop at dawn", "underwater palace", "desert highway", "floating islands",
        "dystopian Tokyo", "cyberpunk Seoul", "ancient temple", "space station", "frozen tundra", "volcanic landscape",
        "bioluminescent forest", "steampunk factory", "art deco ballroom", "post-apocalyptic wasteland", "crystal cave",
        "holographic nightclub", "zero gravity station", "ancient ruins", "mirror dimension", "time-frozen city",
        "neon-lit rain street", "abandoned amusement park", "underground bunker", "floating market", "digital void",
        "cherry blossom garden", "brutalist architecture", "venetian canals", "himalayan monastery"
    ],
    "characters": [
        "lonely hacker", "rebel artist", "time traveler", "android musician", "street dancer", "wandering poet",
        "revenge seeker", "fallen angel", "lost astronaut", "phantom thief", "cursed immortal", "dimension hopper",
        "memory collector", "dream architect", "soul merchant", "reality bender", "shadow assassin", "light keeper",
        "chaos agent", "harmony seeker", "digital ghost", "analog soul", "future prophet", "past hunter",
        "emotion vampire", "hope dealer", "fear eater", "love warrior", "death dancer", "life singer"
    ],
    "aesthetics": [
        "retro 80s", "vaporwave dreams", "dark academia", "y2k nostalgia", "minimalist void", "baroque luxury",
        "glitch art", "neon noir", "pastel goth", "cyberpunk", "afrofuturism", "solarpunk", "dieselpunk",
        "cottagecore nightmare", "liminal space", "dreamcore", "weirdcore", "ethereal maximalism", "brutalist elegance",
        "bio-organic tech", "crystal punk", "holographic minimalism", "dark romanticism", "neo-tokyo", "cyber-shamanic",
        "quantum aesthetic", "retro-futurism", "analog horror", "digital baroque", "neon gothic"
    ],
    "actions": [
        "running through rain", "dancing in fire", "flying over city", "drowning in memories", "breaking free",
        "searching for light", "falling through time", "rising from ashes", "chasing shadows", "embracing the void",
        "shattering reality", "rebuilding self", "transcending dimension", "merging with machine", "escaping simulation",
        "fighting inner demon", "reuniting souls", "sacrificing everything", "discovering truth", "accepting fate",
        "defying gravity", "manipulating time", "bending light", "controlling elements", "summoning power"
    ],
    "times": [
        "midnight", "golden hour", "endless night", "frozen moment", "parallel timeline", "infinite loop",
        "last sunrise", "first snowfall", "summer's end", "dawn of chaos", "twilight zone", "eternal dusk",
        "moment before impact", "second after rebirth", "edge of tomorrow", "yesterday's future", "timeless now",
        "quantum midnight", "fractal dawn", "crystallized second"
    ],
    "trends_2025": [
        "AI awakening", "metaverse escape", "climate dystopia", "gen-z rebellion", "digital detox", "virtual romance",
        "blockchain dreams", "quantum love", "hologram memories", "synthetic emotions", "neural link love", "avatar identity",
        "deep fake reality", "algorithmic fate", "carbon zero future", "biohacked beauty", "crypto collapse", "VR addiction",
        "AI companion bond", "simulation theory", "consciousness upload", "memory marketplace", "emotion NFT", "dream streaming"
    ],
    "cinematic_styles": [
        "Christopher Nolan epic", "Denis Villeneuve atmosphere", "David Fincher darkness", "Wes Anderson symmetry",
        "Wong Kar-wai romance", "Park Chan-wook intensity", "Bong Joon-ho social", "Ridley Scott sci-fi",
        "Guillermo del Toro fantasy", "Terrence Malick poetry", "Nicolas Winding Refn neon", "Gaspar NoÃ© chaos",
        "Kubrick precision", "Tarkovsky meditation", "Lynch surrealism", "Tarantino stylization"
    ],
    "music_moods": [
        "anthemic euphoria", "melancholic beauty", "aggressive energy", "dreamy float", "dark intensity",
        "playful chaos", "intimate whisper", "epic grandeur", "haunting mystery", "rebellious defiance",
        "nostalgic warmth", "futuristic cold", "organic warmth", "synthetic precision", "raw emotion"
    ]
}

def generate_trending_topic():
    """ë”ìš± ë‹¤ì–‘í•œ ì£¼ì œ ìƒì„±"""
    templates = [
        "{character} experiencing {emotion} in a {setting} during {time}, {aesthetic} style, {action}",
        "{emotion} journey of a {character} in {setting}, {aesthetic} vibes, {trend}",
        "{cinematic} inspired: {character} {action} in {setting}, {aesthetic} aesthetic",
        "{trend} era: {character} feeling {emotion}, {setting}, {time}",
        "{aesthetic} music video: {character} in {setting}, {emotion} meets {music_mood}",
        "Visual poem: {character} {action}, {setting} at {time}, {cinematic} cinematography",
        "{music_mood} energy: {character} confronts {emotion} in {setting}, {trend}",
        "Experimental: {character} trapped in {setting}, {aesthetic} meets {cinematic}",
    ]
    template = random.choice(templates)
    return template.format(
        emotion=random.choice(TRENDING_KEYWORDS["emotions"]),
        setting=random.choice(TRENDING_KEYWORDS["settings"]),
        character=random.choice(TRENDING_KEYWORDS["characters"]),
        aesthetic=random.choice(TRENDING_KEYWORDS["aesthetics"]),
        action=random.choice(TRENDING_KEYWORDS["actions"]),
        time=random.choice(TRENDING_KEYWORDS["times"]),
        trend=random.choice(TRENDING_KEYWORDS["trends_2025"]),
        cinematic=random.choice(TRENDING_KEYWORDS["cinematic_styles"]),
        music_mood=random.choice(TRENDING_KEYWORDS["music_moods"])
    )

def get_viral_topic_with_ai(api_key, model_name):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        prompt = """Generate ONE highly creative, viral-worthy music video concept. 
        Be specific, cinematic, and emotionally compelling. Include:
        - Unique character/protagonist
        - Vivid setting/location
        - Core emotion/theme
        - Visual style reference
        Keep it to 2-3 sentences. Make it feel like a blockbuster movie pitch."""
        response = model.generate_content(prompt)
        return response.text.strip().strip('"')
    except:
        return generate_trending_topic()

# --- API í‚¤ ---
def get_api_key(key_name):
    if key_name in st.secrets: return st.secrets[key_name]
    elif os.getenv(key_name): return os.getenv(key_name)
    return None

# --- ì¥ë¥´/ìŠ¤íƒ€ì¼ (í™•ì¥) ---
VIDEO_GENRES = [
    "Action/Thriller", "Sci-Fi Epic", "Dark Fantasy", "Psychological Horror", "Romantic Drama", 
    "Neo-Noir", "Cyberpunk", "Post-Apocalyptic", "Surreal/Abstract", "Music Video (Performance)",
    "Music Video (Narrative)", "Experimental Art Film", "Anime/Animation", "Documentary Style",
    "Found Footage", "One-Shot/Long Take", "Dance Film", "Visual Poem", "Social Commentary",
    "Cosmic Horror", "Magical Realism", "Dystopian Future", "Historical Epic", "Slice of Life"
]

VISUAL_STYLES = [
    "Photorealistic/Cinematic", "Hyperrealistic 8K", "Anime/Manga", "3D Pixar Style", 
    "2D Traditional Animation", "Watercolor Painting", "Oil Painting Classical", "Cyberpunk Neon",
    "Dark Fantasy Gothic", "Pastel Dreamy", "Black & White Film Noir", "Retro 80s VHS",
    "Vaporwave Aesthetic", "Lo-Fi Indie", "High Fashion Editorial", "Gritty Documentary",
    "Surrealist Art", "Minimalist Clean", "Maximalist Baroque", "Glitch Art Digital"
]

MUSIC_GENRES = [
    "Pop", "Rock", "Hip-Hop/Rap", "Electronic/EDM", "R&B/Soul", "Jazz", "Classical",
    "Metal", "Indie", "K-Pop", "Lo-Fi", "Trap", "House", "Techno", "Ambient",
    "Synthwave", "Phonk", "Drill", "Afrobeat", "Latin", "Folk", "Country",
    "Orchestral/Cinematic", "Experimental", "Post-Rock", "Dream Pop", "Shoegaze"
]

# --- ìë™ ì˜ìƒ ì„¤ì • (ì£¼ì œ ê¸°ë°˜) ---
def analyze_topic_for_auto_settings(topic):
    """ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì˜ìƒì¥ë¥´, ë¹„ì£¼ì–¼ìŠ¤íƒ€ì¼, ìŒì•…ì¥ë¥´ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜"""
    topic_lower = topic.lower()

    # í‚¤ì›Œë“œ ë§¤í•‘ ì‚¬ì „
    genre_keywords = {
        0: ["ì•¡ì…˜", "action", "ì „ìŸ", "war", "ì „íˆ¬", "battle", "ì‹¸ì›€", "fight", "ì¶”ê²©", "chase", "í­ë°œ", "explosion"],
        1: ["sf", "sci-fi", "ìš°ì£¼", "space", "ë¯¸ë˜", "future", "ë¡œë´‡", "robot", "ì™¸ê³„ì¸", "alien", "ìš°ì£¼ì„ "],
        2: ["íŒíƒ€ì§€", "fantasy", "ë§ˆë²•", "magic", "ìš©", "dragon", "ê¸°ì‚¬", "knight", "ì—˜í”„", "elf", "ë˜ì „"],
        3: ["ê³µí¬", "horror", "í˜¸ëŸ¬", "ê·€ì‹ ", "ghost", "ì¢€ë¹„", "zombie", "ë¬´ì„œìš´", "scary", "ì‹¬ë¦¬", "psychological"],
        4: ["ì‚¬ë‘", "love", "ì—°ì• ", "romance", "ì´ë³„", "breakup", "ê·¸ë¦¬ì›€", "longing", "ì²«ì‚¬ë‘", "ê³ ë°±"],
        5: ["ëŠì™€ë¥´", "noir", "ë²”ì£„", "crime", "íƒì •", "detective", "ë¯¸ìŠ¤í„°ë¦¬", "mystery", "ì•”í‘ê°€"],
        6: ["ì‚¬ì´ë²„í‘í¬", "cyberpunk", "ë„¤ì˜¨", "neon", "í•´ì»¤", "hacker", "ë””ìŠ¤í† í”¼ì•„", "ë§¤íŠ¸ë¦­ìŠ¤"],
        7: ["ì¢…ë§", "apocalypse", "íí—ˆ", "ruins", "ì„œë°”ì´ë²Œ", "survival", "í™©ë¬´ì§€", "wasteland"],
        8: ["ì¶”ìƒ", "abstract", "ì´ˆí˜„ì‹¤", "surreal", "ê¿ˆ", "dream", "í™˜ê°", "ë¬´ì˜ì‹"],
        9: ["í¼í¬ë¨¼ìŠ¤", "performance", "ë¬´ëŒ€", "stage", "ë¼ì´ë¸Œ", "live", "ì½˜ì„œíŠ¸", "concert"],
        10: ["ìŠ¤í† ë¦¬", "story", "ì´ì•¼ê¸°", "narrative", "ë“œë¼ë§ˆ", "drama", "ì„œì‚¬"],
        11: ["ì‹¤í—˜", "experimental", "ì•„ë°©ê°€ë¥´ë“œ", "avant-garde", "ì˜ˆìˆ ", "art"],
        12: ["ì• ë‹ˆë©”ì´ì…˜", "animation", "ì• ë‹ˆ", "anime", "ë§Œí™”", "cartoon", "ì¼ë³¸", "japan"],
        13: ["ë‹¤í", "documentary", "ì‹¤ì œ", "real", "í˜„ì‹¤", "reality", "ì¸í„°ë·°"],
        16: ["ëŒ„ìŠ¤", "dance", "ì¶¤", "ì•ˆë¬´", "choreography", "ë°œë ˆ", "ballet", "í™í•©ëŒ„ìŠ¤"],
        17: ["ì‹œ", "poem", "ì‹œì ", "poetic", "ê°ì„±", "emotional", "ì„œì •"],
        18: ["ì‚¬íšŒ", "social", "ë¹„íŒ", "critique", "ë©”ì‹œì§€", "message", "í˜„ëŒ€ì‚¬íšŒ"],
        19: ["ìš°ì£¼ê³µí¬", "cosmic", "í¬íˆ´ë£¨", "lovecraft", "ë¯¸ì§€", "unknown"],
        20: ["ë§ˆìˆ ì ", "magical realism", "ê¸°ë¬˜í•œ", "strange", "ì¼ìƒì†ë¹„ì¼ìƒ"],
        21: ["ë¯¸ë˜ë„ì‹œ", "dystopia", "í†µì œì‚¬íšŒ", "ë¹…ë¸Œë¼ë”", "ê°ì‹œ"],
        22: ["ì—­ì‚¬", "historical", "ì‹œëŒ€ê·¹", "ì™•ì¡°", "ì¤‘ì„¸", "ê³ ëŒ€"],
        23: ["ì¼ìƒ", "daily", "slice of life", "í‰ë²”í•œ", "ì†Œì†Œí•œ"]
    }

    visual_keywords = {
        0: ["ì‹¤ì‚¬", "realistic", "ì˜í™”", "cinematic", "í˜„ì‹¤ì "],
        1: ["ì´ˆê³ í™”ì§ˆ", "8k", "4k", "í•˜ì´í¼", "hyper", "ê·¹ì‚¬ì‹¤"],
        2: ["ì• ë‹ˆ", "anime", "ë§ê°€", "manga", "ì¼ë³¸ì• ë‹ˆ", "ì…€ì• ë‹ˆ"],
        3: ["3d", "í”½ì‚¬", "pixar", "ë””ì¦ˆë‹ˆ", "disney", "cg"],
        4: ["2d", "ì…€", "ì „í†µ", "hand-drawn"],
        5: ["ìˆ˜ì±„í™”", "watercolor", "íŒŒìŠ¤í…”", "ë¶€ë“œëŸ¬ìš´"],
        6: ["ìœ í™”", "oil painting", "ê³ ì „", "classical", "ë¥´ë„¤ìƒìŠ¤"],
        7: ["ì‚¬ì´ë²„í‘í¬", "cyberpunk", "ë„¤ì˜¨", "neon", "ë¯¸ë˜ë„ì‹œ"],
        8: ["ë‹¤í¬íŒíƒ€ì§€", "dark fantasy", "ê³ ë”•", "gothic", "ì–´ë‘ "],
        9: ["íŒŒìŠ¤í…”", "pastel", "dreamy", "ëª½í™˜", "ë¶€ë“œëŸ¬ìš´"],
        10: ["í‘ë°±", "b&w", "black and white", "ëª¨ë…¸í¬ë¡¬", "í•„ë¦„ëˆ„ì•„ë¥´"],
        11: ["ë ˆíŠ¸ë¡œ", "retro", "80ë…„ëŒ€", "80s", "vhs", "ë³µê³ "],
        12: ["ë² ì´í¼ì›¨ì´ë¸Œ", "vaporwave", "ì¦ê¸°íŒŒ", "í•‘í¬", "ë³´ë¼"],
        13: ["ë¡œíŒŒì´", "lo-fi", "ì¸ë””", "indie", "ê·¸ëŸ°ì§€"],
        14: ["íŒ¨ì…˜", "fashion", "í•˜ì´íŒ¨ì…˜", "ì—ë””í† ë¦¬ì–¼", "ë³´ê·¸"],
        15: ["ë‹¤í", "documentary", "ê±°ì¹œ", "gritty", "ë¦¬ì–¼"],
        16: ["ì´ˆí˜„ì‹¤", "surrealist", "ë‹¬ë¦¬", "ë§ˆê·¸ë¦¬íŠ¸", "ê¸°ë¬˜í•œ"],
        17: ["ë¯¸ë‹ˆë©€", "minimal", "ì‹¬í”Œ", "simple", "ê¹”ë”í•œ"],
        18: ["ë§¥ì‹œë©€", "maximalist", "í™”ë ¤í•œ", "ë°”ë¡œí¬", "baroque"],
        19: ["ê¸€ë¦¬ì¹˜", "glitch", "ë””ì§€í„¸", "digital", "ë…¸ì´ì¦ˆ"]
    }

    music_keywords = {
        0: ["íŒ", "pop", "ëŒ€ì¤‘", "mainstream"],
        1: ["ë¡", "rock", "ê¸°íƒ€", "guitar", "ë°´ë“œ"],
        2: ["í™í•©", "hip-hop", "ë©", "rap", "ë¹„íŠ¸"],
        3: ["ì¼ë ‰", "electronic", "edm", "í´ëŸ½", "club"],
        4: ["ì•Œì•¤ë¹„", "r&b", "ì†Œìš¸", "soul", "ê°ë¯¸ë¡œìš´"],
        5: ["ì¬ì¦ˆ", "jazz", "ìŠ¤ìœ™", "swing", "ë¸”ë£¨ìŠ¤"],
        6: ["í´ë˜ì‹", "classical", "ì˜¤ì¼€ìŠ¤íŠ¸ë¼", "í”¼ì•„ë…¸", "ë°”ì´ì˜¬ë¦°"],
        7: ["ë©”íƒˆ", "metal", "í—¤ë¹„", "heavy", "í•˜ë“œë¡"],
        8: ["ì¸ë””", "indie", "ë…ë¦½", "alternative"],
        9: ["ì¼€ì´íŒ", "k-pop", "kpop", "ì•„ì´ëŒ", "idol"],
        10: ["ë¡œíŒŒì´", "lo-fi", "lofi", "ì”ì”í•œ", "ê³µë¶€"],
        11: ["íŠ¸ë©", "trap", "808", "ë² ì´ìŠ¤"],
        12: ["í•˜ìš°ìŠ¤", "house", "ë””ìŠ¤ì½”", "disco"],
        13: ["í…Œí¬ë…¸", "techno", "ì–¸ë”ê·¸ë¼ìš´ë“œ"],
        14: ["ì•°ë¹„ì–¸íŠ¸", "ambient", "ë¶„ìœ„ê¸°", "ë°°ê²½ìŒì•…"],
        15: ["ì‹ ìŠ¤ì›¨ì´ë¸Œ", "synthwave", "ë ˆíŠ¸ë¡œ", "80ë…„ëŒ€ìŒì•…"],
        16: ["íí¬", "phonk", "drift", "ë“œë¦¬í”„íŠ¸"],
        17: ["ë“œë¦´", "drill", "ì˜êµ­", "uk"],
        18: ["ì•„í”„ë¡œë¹„íŠ¸", "afrobeat", "ì•„í”„ë¦¬ì¹´"],
        19: ["ë¼í‹´", "latin", "ë ˆê²Œí†¤", "ì‚´ì‚¬"],
        20: ["í¬í¬", "folk", "ì–´ì¿ ìŠ¤í‹±", "acoustic"],
        21: ["ì»¨íŠ¸ë¦¬", "country", "ë¯¸êµ­ë‚¨ë¶€"],
        22: ["ì˜¤ì¼€ìŠ¤íŠ¸ë¼", "orchestral", "cinematic", "ì˜í™”ìŒì•…", "ì›…ì¥"],
        23: ["ì‹¤í—˜ìŒì•…", "experimental", "ë…¸ì´ì¦ˆ"],
        24: ["í¬ìŠ¤íŠ¸ë¡", "post-rock", "ìŠ¬ë¡œìš°"],
        25: ["ë“œë¦¼íŒ", "dream pop", "ëª½í™˜ì "],
        26: ["ìŠˆê²Œì´ì§•", "shoegaze", "ë…¸ì´ì¦ˆíŒ"]
    }

    def find_best_match(keywords_dict, default=0):
        scores = {idx: 0 for idx in keywords_dict}
        for idx, keywords in keywords_dict.items():
            for keyword in keywords:
                if keyword in topic_lower:
                    scores[idx] += 1

        max_score = max(scores.values())
        if max_score > 0:
            for idx, score in scores.items():
                if score == max_score:
                    return idx
        return default

    genre_idx = find_best_match(genre_keywords, 0)
    visual_idx = find_best_match(visual_keywords, 0)
    music_idx = find_best_match(music_keywords, 0)

    # ì¥ë¥´-ìŠ¤íƒ€ì¼ ì—°ê´€ì„± ë³´ì •
    genre_visual_mapping = {
        6: 7,   # Cyberpunk â†’ Cyberpunk Neon
        2: 8,   # Dark Fantasy â†’ Dark Fantasy Gothic
        12: 2,  # Anime/Animation â†’ Anime/Manga
        3: 8,   # Psychological Horror â†’ Dark Fantasy Gothic
        5: 10,  # Neo-Noir â†’ Black & White Film Noir
        22: 6,  # Historical Epic â†’ Oil Painting Classical
    }

    genre_music_mapping = {
        6: 15,  # Cyberpunk â†’ Synthwave
        12: 9,  # Anime/Animation â†’ K-Pop or J-Pop related
        22: 22, # Historical Epic â†’ Orchestral/Cinematic
        3: 14,  # Psychological Horror â†’ Ambient
        1: 3,   # Sci-Fi Epic â†’ Electronic/EDM
    }

    # ìŠ¤íƒ€ì¼ì´ ê¸°ë³¸ê°’ì´ë©´ ì¥ë¥´ì— ë§ì¶° ë³´ì •
    if visual_idx == 0 and genre_idx in genre_visual_mapping:
        visual_idx = genre_visual_mapping[genre_idx]

    if music_idx == 0 and genre_idx in genre_music_mapping:
        music_idx = genre_music_mapping[genre_idx]

    return genre_idx, visual_idx, music_idx

# --- ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ ê°•ì¡° (í¬í† ë¦¬ì–¼ë¦¬ìŠ¤í‹± ëŒ€í­ ê°•í™”) ---
def get_visual_style_emphasis(visual_style):
    # í¬í† ë¦¬ì–¼ë¦¬ìŠ¤í‹± ê³„ì—´ ê°•ë ¥í•œ í”„ë¡¬í”„íŠ¸
    photo_emphasis = """(EXTREMELY DETAILED REAL PHOTO:1.5), (8k resolution:1.2), (photorealistic:1.4), 
RAW photo, Fujifilm XT3, shot on 50mm lens, f/1.8, natural skin texture, visible pores, soft lighting, 
detailed eyes, distinct facial features, hyper-detailed, no CGI, no 3D render look, 
authentic human imperfections, cinematic lighting, masterpiece, best quality"""

    style_map = {
        "Photorealistic/Cinematic": photo_emphasis,
        "Hyperrealistic 8K": photo_emphasis + ", RED V-RAPTOR 8K, documentary style",
        
        "Anime/Manga": """anime style, manga illustration, cel-shaded, vibrant anime colors, 
expressive anime eyes, clean linework, anime aesthetic, Studio Ghibli quality,
Makoto Shinkai lighting, detailed anime backgrounds""",
        
        "3D Pixar Style": """3D rendered, Pixar Animation Studios quality, CGI animation, 
smooth gradients, subsurface scattering, ray-traced lighting, 
Disney/Pixar character design, expressive 3D characters""",
        
        "Cyberpunk Neon": """cyberpunk aesthetic, neon lights, synthwave colors, 
futuristic cityscape, rain-slicked streets, holographic advertisements,
Blade Runner 2049 cinematography, volumetric fog, RGB lighting,
dark with vibrant neon accents, tech-noir atmosphere""",
        
        "Dark Fantasy Gothic": """dark fantasy, gothic architecture, moody atmosphere, 
dramatic chiaroscuro lighting, mysterious fog, medieval dark aesthetics,
Game of Thrones visual quality, dark romanticism, ominous shadows""",
        
        "Black & White Film Noir": """black and white cinematography, high contrast,
dramatic shadows, film noir lighting, 1940s Hollywood style,
venetian blind shadows, fog-filled streets, classic cinema look""",
        
        "Retro 80s VHS": """1980s aesthetic, VHS quality, scan lines, chromatic aberration,
neon colors, analog warmth, retro futurism, Stranger Things vibe,
practical effects look, vintage film grain""",
        
        "High Fashion Editorial": """high fashion photography, Vogue editorial quality,
dramatic fashion lighting, avant-garde styling, luxury aesthetic,
shot by Mario Testino, couture fashion, editorial composition""",
        
        "Surrealist Art": """surrealist art style, Salvador Dali inspired, 
dreamlike imagery, impossible geometry, melting reality,
symbolic visual metaphors, subconscious imagery, Magritte influence"""
    }
    return style_map.get(visual_style, f"{visual_style}, high quality, professional")

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    execution_mode = st.radio("ì‹¤í–‰ ë°©ì‹", ["API ìë™ ì‹¤í–‰", "ìˆ˜ë™ ëª¨ë“œ (ë¬´ì œí•œ)"], index=0)
    st.markdown("---")

    gemini_key = None
    gemini_model = None
    segmind_key = None
    
    if execution_mode == "API ìë™ ì‹¤í–‰":
        # Gemini Key
        gemini_key = get_api_key("GOOGLE_API_KEY") or get_api_key("GEMINI_API_KEY")
        if gemini_key:
            st.success("âœ… Gemini Key ì—°ê²°ë¨")
        else:
            gemini_key = st.text_input("Gemini API Key", type="password")
        
        # Segmind Key (ì¶”ê°€ë¨)
        segmind_key = get_api_key("SEGMIND_API_KEY")
        if segmind_key:
            st.success("âœ… Segmind Key ì—°ê²°ë¨")
        else:
            segmind_key = st.text_input("Segmind API Key (ì„ íƒ)", type="password")

        # ìµœì‹  Gemini API ëª¨ë¸ (2025)
        model_options = ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
        gemini_model = st.selectbox("ëª¨ë¸", model_options, index=0)
    
    st.markdown("---")
    st.subheader("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±")
    auto_generate = st.checkbox("ìë™ ì´ë¯¸ì§€ ìƒì„±", value=False)
    infinite_retry = st.checkbox("ë¬´í•œ ì¬ì‹œë„", value=False)
    
    # ì´ë¯¸ì§€ ê³µê¸‰ì ì„ íƒ (Segmind ë³µêµ¬ ë° ê¸°ë³¸ê°’ ì„¤ì •)
    image_provider = st.selectbox("ì—”ì§„", ["Segmind (ê¸°ë³¸/ì•ˆì •)", "Pollinations Flux", "Pollinations Turbo âš¡"], index=0)
    
    if not infinite_retry:
        max_retries = st.slider("ì¬ì‹œë„", 1, 10, 3)
    else:
        max_retries = 999

    st.markdown("---")
    if st.button("ğŸ—‘ï¸ ì „ì²´ ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

    st.markdown("---")

    # ìë™ ìŠ¤íƒ€ì¼ ì„¤ì • (ì ‘ì„ ìˆ˜ ìˆëŠ” ë©”ë‰´)
    with st.expander("ğŸ”„ ìë™ ìŠ¤íƒ€ì¼ ì„¤ì •", expanded=False):
        st.caption("ì£¼ì œ ìë™ìƒì„± ì‹œ ì²´í¬ëœ í•­ëª©ì„ ìë™ ì„¤ì •í•©ë‹ˆë‹¤")
        auto_genre_enabled = st.checkbox("ğŸ¬ ì˜ìƒ ì¥ë¥´ ìë™", value=st.session_state.get('auto_genre_enabled', False), key='auto_genre_enabled')
        auto_visual_enabled = st.checkbox("ğŸ¨ ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ ìë™", value=st.session_state.get('auto_visual_enabled', False), key='auto_visual_enabled')
        auto_music_enabled = st.checkbox("ğŸµ ìŒì•… ì¥ë¥´ ìë™", value=st.session_state.get('auto_music_enabled', False), key='auto_music_enabled')

# --- ë©”ì¸ í™”ë©´ ---
st.title("ğŸ¬ AI MV Director Pro")
st.caption("ì—…ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ë®¤ì§ë¹„ë””ì˜¤ ê¸°íš ì‹œìŠ¤í…œ")

ratio_map = {
    "16:9 (Cinema)": (1024, 576),
    "9:16 (Portrait)": (576, 1024),
    "1:1 (Square)": (1024, 1024),
    "21:9 (Ultrawide)": (1024, 439),
    "4:3 (Classic)": (1024, 768),
}

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
defaults = {
    'scene_count': 8,
    'total_duration': 60,
    'seconds_per_scene': 5,
    'random_topic': "",
    'plan_data': None,
    'generated_images': {},
    'turntable_images': {},
    'auto_genre_enabled': False,
    'auto_visual_enabled': False,
    'auto_music_enabled': False,
    'selected_genre_idx': 0,
    'selected_visual_idx': 0,
    'selected_music_idx': 0
}
for key, val in defaults.items():
    if key not in st.session_state:
        st.session_state[key] = val

with st.expander("ğŸ“ í”„ë¡œì íŠ¸ ì„¤ì •", expanded=True):
    # ë°”ì´ëŸ´ ì£¼ì œ ìƒì„±
    st.markdown("<div class='trend-box'>", unsafe_allow_html=True)
    st.markdown("### ğŸ”¥ ë°”ì´ëŸ´ ì£¼ì œ ìƒì„±ê¸°")
    
    # ìë™ ìŠ¤íƒ€ì¼ ì„¤ì • ì ìš© í•¨ìˆ˜
    def apply_auto_style_settings(topic_text):
        """ì²´í¬ëœ í•­ëª©ì— ëŒ€í•´ ì£¼ì œ ê¸°ë°˜ ìë™ ìŠ¤íƒ€ì¼ ì„¤ì • ì ìš©"""
        if topic_text:
            genre_idx, visual_idx, music_idx = analyze_topic_for_auto_settings(topic_text)
            if st.session_state.get('auto_genre_enabled', False):
                st.session_state.selected_genre_idx = genre_idx
            if st.session_state.get('auto_visual_enabled', False):
                st.session_state.selected_visual_idx = visual_idx
            if st.session_state.get('auto_music_enabled', False):
                st.session_state.selected_music_idx = music_idx

    col_t1, col_t2, col_t3 = st.columns(3)
    with col_t1:
        if st.button("ğŸ² ëœë¤ ìƒì„±", use_container_width=True):
            st.session_state.random_topic = generate_trending_topic()
            apply_auto_style_settings(st.session_state.random_topic)
            st.rerun()
    with col_t2:
        if st.button("ğŸ²ğŸ² 5ê°œ ìƒì„±", use_container_width=True):
            topics = [generate_trending_topic() for _ in range(5)]
            st.session_state.random_topic = "\n---\n".join(topics)
            apply_auto_style_settings(topics[0])  # ì²« ë²ˆì§¸ ì£¼ì œ ê¸°ì¤€
            st.rerun()
    with col_t3:
        if st.button("ğŸ¤– AI ìƒì„±", use_container_width=True):
            if gemini_key:
                st.session_state.random_topic = get_viral_topic_with_ai(gemini_key, gemini_model)
                apply_auto_style_settings(st.session_state.random_topic)
                st.rerun()
            else:
                st.warning("API í‚¤ í•„ìš”")
    
    if st.session_state.random_topic:
        st.info(f"ğŸ’¡ {st.session_state.random_topic}")
    st.markdown("</div>", unsafe_allow_html=True)

    # ì¥ë¥´/ìŠ¤íƒ€ì¼ ëœë¤ ì„ íƒ ë²„íŠ¼ (form ë°–)
    st.markdown("#### ğŸ² ì¥ë¥´/ìŠ¤íƒ€ì¼ ëœë¤ ì„ íƒ")
    col_r1, col_r2, col_r3, col_r4 = st.columns([1, 1, 1, 1])
    with col_r1:
        if st.button("ğŸ¬ ì˜ìƒì¥ë¥´", use_container_width=True, key="rand_genre"):
            st.session_state.selected_genre_idx = random.randint(0, len(VIDEO_GENRES) - 1)
            st.rerun()
    with col_r2:
        if st.button("ğŸ¨ ë¹„ì£¼ì–¼", use_container_width=True, key="rand_visual"):
            st.session_state.selected_visual_idx = random.randint(0, len(VISUAL_STYLES) - 1)
            st.rerun()
    with col_r3:
        if st.button("ğŸµ ìŒì•…ì¥ë¥´", use_container_width=True, key="rand_music"):
            st.session_state.selected_music_idx = random.randint(0, len(MUSIC_GENRES) - 1)
            st.rerun()
    with col_r4:
        if st.button("ğŸ² ì „ì²´ ëœë¤", use_container_width=True, key="rand_all"):
            st.session_state.selected_genre_idx = random.randint(0, len(VIDEO_GENRES) - 1)
            st.session_state.selected_visual_idx = random.randint(0, len(VISUAL_STYLES) - 1)
            st.session_state.selected_music_idx = random.randint(0, len(MUSIC_GENRES) - 1)
            st.rerun()

    # íƒ€ì„ë¼ì¸ ì„¤ì • (form ë°–ì—ì„œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸)
    st.markdown("#### â±ï¸ íƒ€ì„ë¼ì¸ ì„¤ì •")
    duration_mode = st.radio("ëŸ°ë‹íƒ€ì„ ì„¤ì • ë°©ì‹", ["ì´ ëŸ°ë‹íƒ€ì„ ê¸°ì¤€", "ì”¬ ê°œìˆ˜ ì§ì ‘ ì§€ì •"],
                             horizontal=True, key="duration_mode")

    if duration_mode == "ì´ ëŸ°ë‹íƒ€ì„ ê¸°ì¤€":
        col_d1, col_d2, col_d3 = st.columns(3)
        with col_d1:
            total_duration = st.number_input("ì´ ëŸ°ë‹íƒ€ì„ (ì´ˆ)", min_value=10, max_value=600,
                                            value=st.session_state.total_duration, step=5,
                                            key="input_total_duration")
        with col_d2:
            seconds_per_scene = st.slider("ì»·ë‹¹ ê¸¸ì´ (ì´ˆ)", 2, 20, st.session_state.seconds_per_scene,
                                         key="input_seconds_per_scene")
        with col_d3:
            scene_count = max(1, int(total_duration / seconds_per_scene))
            st.markdown(f"""
            <div class='realtime-calc'>
                ğŸ“Š ì´ <b>{scene_count}</b>ê°œ ì”¬<br>
                <small>{total_duration}ì´ˆ Ã· {seconds_per_scene}ì´ˆ</small>
            </div>
            """, unsafe_allow_html=True)

        st.session_state.scene_count = scene_count
        st.session_state.total_duration = total_duration
        st.session_state.seconds_per_scene = seconds_per_scene
    else:
        col_s1, col_s2, col_s3 = st.columns(3)
        with col_s1:
            scene_count = st.number_input("ì”¬ ê°œìˆ˜", min_value=2, max_value=50,
                                         value=st.session_state.scene_count, step=1,
                                         key="input_scene_count")
        with col_s2:
            seconds_per_scene = st.slider("ì»·ë‹¹ ê¸¸ì´ (ì´ˆ)", 2, 20, st.session_state.seconds_per_scene,
                                         key="input_seconds_per_scene_2")
        with col_s3:
            total_duration = scene_count * seconds_per_scene
            st.markdown(f"""
            <div class='realtime-calc'>
                â±ï¸ ì´ <b>{total_duration}</b>ì´ˆ<br>
                <small>({total_duration//60}ë¶„ {total_duration%60}ì´ˆ)</small>
            </div>
            """, unsafe_allow_html=True)

        st.session_state.scene_count = scene_count
        st.session_state.seconds_per_scene = seconds_per_scene
        st.session_state.total_duration = total_duration

    with st.form("project_form"):
        topic = st.text_area("ğŸ¯ ì˜ìƒ ì£¼ì œ/ì»¨ì…‰", height=120, 
                            value=st.session_state.random_topic if st.session_state.random_topic else "",
                            placeholder="ë®¤ì§ë¹„ë””ì˜¤ì˜ ì£¼ì œ, ìŠ¤í† ë¦¬, ë¶„ìœ„ê¸°ë¥¼ ìƒì„¸íˆ ì…ë ¥í•˜ì„¸ìš”...")
        
        st.markdown("---")
        
        # JSON í”„ë¡œí•„ ì˜µì…˜
        col_opt1, col_opt2 = st.columns(2)
        with col_opt1:
            use_json_profiles = st.checkbox("ğŸ¯ JSON í”„ë¡œí•„ (ê·¹ë„ ë””í…Œì¼)", value=True)
        with col_opt2:
            expert_mode = st.checkbox("ğŸ† ì „ë¬¸ê°€ ëª¨ë“œ (ì‹¬ì¸µ ë¶„ì„)", value=True)

        st.markdown("---")

        # ì¥ë¥´/ìŠ¤íƒ€ì¼ ì„ íƒ (session_state ì¸ë±ìŠ¤ ì‚¬ìš©)
        col_g1, col_g2, col_g3 = st.columns(3)
        with col_g1:
            selected_genre = st.selectbox("ğŸ¬ ì˜ìƒ ì¥ë¥´", VIDEO_GENRES,
                index=st.session_state.selected_genre_idx)
        with col_g2:
            selected_visual = st.selectbox("ğŸ¨ ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼", VISUAL_STYLES,
                index=st.session_state.selected_visual_idx)
        with col_g3:
            selected_music = st.selectbox("ğŸµ ìŒì•… ì¥ë¥´", MUSIC_GENRES,
                index=st.session_state.selected_music_idx)

        st.markdown("---")

        # í™”ë©´ ë¹„ìœ¨
        aspect_ratio = st.selectbox("ğŸï¸ í™”ë©´ ë¹„ìœ¨", list(ratio_map.keys()), index=0)
        image_width, image_height = ratio_map[aspect_ratio]

        # íƒ€ì„ë¼ì¸ ì •ë³´ëŠ” form ë°–ì—ì„œ ì„¤ì •ëœ session_state ê°’ ì‚¬ìš©
        scene_count = st.session_state.scene_count
        seconds_per_scene = st.session_state.seconds_per_scene

        st.markdown("---")
        
        # ìŠ¤í† ë¦¬ ì˜µì…˜
        st.markdown("**ğŸ“– ìŠ¤í† ë¦¬ êµ¬ì„± ìš”ì†Œ**")
        cols = st.columns(4)
        with cols[0]:
            use_arc = st.checkbox("ê¸°ìŠ¹ì „ê²° êµ¬ì¡°", value=True)
            use_sensory = st.checkbox("ê°ê°ì  ë¬˜ì‚¬", value=True)
        with cols[1]:
            use_trial = st.checkbox("ì‹œë ¨/ê°ˆë“±", value=True)
            use_dynamic = st.checkbox("ì—­ë™ì  ì „ê°œ", value=True)
        with cols[2]:
            use_emotional = st.checkbox("ê°ì • ë³€í™”ê³¡ì„ ", value=True)
            use_climax = st.checkbox("í´ë¼ì´ë§¥ìŠ¤ êµ¬ì¶•", value=True)
        with cols[3]:
            use_symbolic = st.checkbox("ìƒì§•/ë©”íƒ€í¬", value=True)
            use_twist = st.checkbox("ë°˜ì „ ìš”ì†Œ", value=False)
        
        st.markdown("---")
        submit_btn = st.form_submit_button("ğŸš€ í”„ë¡œì íŠ¸ ìƒì„±", use_container_width=True, type="primary")

# ------------------------------------------------------------------
# JSON ì •ë¦¬ í•¨ìˆ˜
# ------------------------------------------------------------------
def clean_json_text(text):
    match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
    if match:
        text = match.group(1)
    else:
        match = re.search(r"```\s*(.*?)\s*```", text, re.DOTALL)
        if match:
            text = match.group(1)
    
    text = text.strip()
    text = re.sub(r',\s*}', '}', text)
    text = re.sub(r',\s*]', ']', text)
    text = re.sub(r'//.*?\n', '\n', text)
    
    # JSON ë¬¸ìì—´ ë‚´ì˜ ì œì–´ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    def escape_control_chars_in_strings(json_str):
        result = []
        in_string = False
        escape_next = False
        
        for char in json_str:
            if escape_next:
                result.append(char)
                escape_next = False
                continue
            
            if char == '\\':
                result.append(char)
                escape_next = True
                continue
            
            if char == '"':
                in_string = not in_string
                result.append(char)
                continue
            
            if in_string:
                if char == '\n':
                    result.append('\\n')
                elif char == '\r':
                    result.append('\\r')
                elif char == '\t':
                    result.append('\\t')
                elif ord(char) < 32:
                    result.append(f'\\u{ord(char):04x}')
                else:
                    result.append(char)
            else:
                result.append(char)
        
        return ''.join(result)
    
    text = escape_control_chars_in_strings(text)
    return text

# ------------------------------------------------------------------
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì „ë¬¸ê°€ ìˆ˜ì¤€ - ìˆ˜ì •ë¨)
# ------------------------------------------------------------------
def get_system_prompt(topic, scene_count, options, genre, visual_style, music_genre, use_json, expert_mode, seconds_per_scene):
    story_elements = []
    if options.get('use_arc'): story_elements.append("three-act structure with setup-confrontation-resolution")
    if options.get('use_sensory'): story_elements.append("rich sensory details (visual, auditory, tactile)")
    if options.get('use_dynamic'): story_elements.append("dynamic pacing with rhythm variations")
    if options.get('use_emotional'): story_elements.append("emotional arc with clear beats")
    if options.get('use_climax'): story_elements.append("building tension to powerful climax")
    if options.get('use_trial'): story_elements.append("protagonist trials and obstacles")
    if options.get('use_symbolic'): story_elements.append("symbolic imagery and visual metaphors")
    if options.get('use_twist'): story_elements.append("unexpected twist or revelation")
    
    story_instruction = ", ".join(story_elements) if story_elements else "cinematic narrative flow"
    visual_emphasis = get_visual_style_emphasis(visual_style)
    
    expert_instruction = ""
    if expert_mode:
        expert_instruction = """

EXPERT MODE - INDUSTRY PROFESSIONAL STANDARDS:

You are working at the level of top-tier music video directors (Hype Williams, Dave Meyers, Joseph Kahn, CHEZ, Woogie Kim).

CINEMATOGRAPHY MASTERY:
- Camera movements: Specify exact dolly/crane/steadicam/gimbal movements with timing
- Lens choices: Indicate focal length (14mm wide, 50mm standard, 85mm portrait, 200mm telephoto)
- Depth of field: Specify f-stop for each shot (f/1.4 shallow, f/8 deep)
- Lighting setups: Key, fill, rim, practical lights with color temperature (2700K warm, 5600K daylight)

COLOR SCIENCE:
- Color palette: Specify exact HEX codes for dominant, secondary, accent colors
- LUT reference: Reference specific color grades (Teal & Orange, Film Noir, Kodak Vision3)
- Contrast ratio: Specify shadow/highlight relationship
"""

    # ì‹¤ì‚¬ ê°•ì¡° (ê°•ë ¥í•œ ê·œì¹™ ì¶”ê°€)
    photorealistic_extra = ""
    if "Photorealistic" in visual_style or "Hyperrealistic" in visual_style:
        photorealistic_extra = """

CRITICAL - PHOTOREALISTIC REQUIREMENTS (MUST FOLLOW):
ALL prompts MUST include:
- "RAW photo, 8k resolution, photorealistic, dslr, soft lighting, high quality, film grain"
- "REAL HUMAN, natural skin texture, visible pores, imperfections, peach fuzz, realistic eyes"
- "No CGI, No 3D render look, No illustration style"
- "Shot on Fujifilm XT3 or ARRI Alexa"
"""

    json_detail = ""
    if use_json:
        json_detail = f"""

ULTRA-DETAILED JSON PROFILES (SOURCE OF TRUTH - STRONGEST ENFORCEMENT):

1. **SOURCE OF TRUTH RULE**: The 'json_profile' field is the ONLY valid source for physical appearance.
2. **NEGATIVE CONSTRAINT FOR SCENES**: In the 'scenes' -> 'image_prompt' field, you MUST NOT describe the character's appearance (hair color, clothes, face). 
   - **WRONG**: "A handsome man with blue hair and a leather jacket running in the rain."
   - **CORRECT**: "A man running in the rain, dynamic angle, intense expression."
   (The system will automatically INJECT the detailed description from 'json_profile' at the beginning of the prompt. If you repeat it, it causes conflicts.)

3. **MANDATORY**: You MUST generate a turntable entry for **EVERY** single character, location, prop, and vehicle that appears.
4. **DETAIL**: Provide specific HEX codes, materials, brands, and exact measurements.

For CHARACTERS:
{{
  "physical": {{ "age": "exact age", "height_cm": number, "body_type": "detailed", "skin_tone": "#HEX", "skin_texture": "pores/freckles/scars" }},
  "face": {{ "shape": "...", "eyes": {{"color": "#HEX", "shape": "..."}}, "nose": "...", "lips": "...", "hair": {{"color": "#HEX", "style": "..."}} }},
  "clothing": {{ "top": {{"color": "#HEX", "material": "..."}}, "bottom": "...", "shoes": "...", "accessories": "..." }},
  "expression": "default emotional state"
}}

For LOCATIONS:
{{
  "location_type": "exact place",
  "architecture": "style and materials",
  "lighting": {{"time": "HH:MM", "source": "sun/neon", "color_temp": "K"}},
  "palette": {{"dominant": "#HEX", "accent": "#HEX"}}
}}
"""

    turntable_instruction = """

TURNTABLE REFERENCE SHEETS (COMPREHENSIVE & MANDATORY):

You MUST create turntable entries for ALL distinct elements.

FOR EACH CHARACTER (Mandatory Views):
- View 1: "full_turntable" -> PROMPT MUST BE: "character sheet, split screen, 4 distinct views, front view, side view, back view, 3/4 view, same character in all views, full body shot, white background, high resolution"
- View 2: "face_detail" (Extreme close-up, pore details, eyes)
- View 3: "expression_sheet" (Neutral, Joy, Anger, Sorrow, Surprise)
- View 4: "fashion_detail" (Clothing texture, shoes, accessories)
- View 5: "cinematic_portrait" (Best lighting, shallow depth of field)

FOR EACH LOCATION:
- View 1: "establishing_shot" (Wide angle, entire scale)
- View 2: "lighting_study" (Same angle, Day vs Night vs Golden Hour)
- View 3: "texture_details" (Wall materials, floor, key props)

FOR OBJECTS/VEHICLES:
- View 1: "studio_product_shot" (Clean background, 3 angles)
- View 2: "in_situ" (Object in the scene environment)
"""

    video_prompt_instruction = """
VIDEO PROMPT UPGRADE (CRITICAL):
The 'video_prompt' field must be highly detailed for AI Video Generators (Runway Gen-2, Pika, Kling).
Format: "[Camera Movement] + [Subject Action] + [Physics/Environment] + [Technical Specs]"
Example: "Slow dolly zoom in on character's eye, tear rolling down cheek, hair blowing gently in wind, rain falling in background, volumetric lighting, 8k resolution, high fidelity, 120fps smooth motion, shallow depth of field."
NEVER use simple phrases like "Man walking". Be specific about speed, weight, lighting changes, and atmosphere.
"""

    return f"""You are an ELITE music video director working at the highest industry standards.
Create an ULTRA-DETAILED production plan in VALID JSON format.

PROJECT BRIEF:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Theme: "{topic}"
Genre: {genre}
Visual Style: {visual_style}
Music Genre: {music_genre}
Duration: {scene_count} scenes Ã— {seconds_per_scene} seconds
Story Elements: {story_instruction}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

VISUAL STYLE ENFORCEMENT:
ALL image prompts MUST begin with: "{visual_emphasis}"
{photorealistic_extra}
{expert_instruction}
{json_detail}
{turntable_instruction}
{video_prompt_instruction}

JSON FORMAT RULES:
- Use double quotes ONLY
- NO trailing commas
- NO comments
- Escape special characters

RETURN THIS EXACT JSON STRUCTURE:
{{
  "project_title": "Title in Korean",
  "project_title_en": "Title in English",
  "logline": "One-sentence concept in Korean",
  "logline_en": "One-sentence concept in English",
  "director_vision": "2-3 sentences about artistic vision",
  
  "youtube": {{
    "title": "Viral title",
    "description": "SEO description",
    "hashtags": "tags..."
  }},
  
  "music": {{
    "style": "Korean description",
    "style_tags": "genre, mood, bpm",
    "vocal_direction": "details...",
    "instrumentation": "details...",
    "song_structure": "intro-verse-chorus...",
    "lyrics_full": "lyrics...",
    "suno_prompt_combined": "full prompt..."
  }},
  
  "turntable": {{
    "characters": [
      {{
        "id": "char1",
        "name": "Name",
        "name_en": "Name English",
        "json_profile": {{ ...FULL PHYSICAL/CLOTHING PROFILE... }},
        "views": [
            {{ "view_type": "full_turntable", "prompt": "{visual_emphasis}, character sheet, split screen, 4 distinct views, front view, side view, back view, 3/4 view, same character, full body, white background" }},
            {{ "view_type": "face_detail", "prompt": "{visual_emphasis}, extreme close up, face detail..." }},
            {{ "view_type": "expression_sheet", "prompt": "..." }},
            {{ "view_type": "fashion_detail", "prompt": "..." }},
            {{ "view_type": "cinematic_portrait", "prompt": "..." }}
        ]
      }}
      // GENERATE OBJECTS FOR ALL CHARACTERS
    ],
    "locations": [
      {{
        "id": "loc1",
        "name": "Name",
        "json_profile": {{ ...FULL LOCATION PROFILE... }},
        "views": [
            {{ "view_type": "establishing_shot", "prompt": "..." }},
            {{ "view_type": "lighting_study", "prompt": "..." }},
            {{ "view_type": "texture_details", "prompt": "..." }}
        ]
      }}
      // GENERATE OBJECTS FOR ALL LOCATIONS
    ],
    "props": [
      {{
        "id": "prop1",
        "name": "Name",
        "json_profile": {{ ... }},
        "views": [ ... ]
      }}
    ],
    "vehicles": []
  }},
  
  "scenes": [
    {{
      "scene_num": 1,
      "timecode": "00:00-...",
      "act": "1",
      "action": "Description in Korean",
      "emotion": "Emotion",
      "camera": {{ "shot_type": "...", "movement": "...", "lens": "..." }},
      "used_turntables": ["char1", "loc1"],
      "image_prompt": "{visual_emphasis}, [SCENE ACTION], [CAMERA ANGLE]. (DO NOT describe appearance here. Focus on action.)",
      "video_prompt": "CRITICAL: Highly detailed prompt for Runway/Pika. Camera movement + Action + Physics + Technicals. Minimum 20 words."
    }}
  ]
}}

Generate exactly {scene_count} scenes.
ENSURE ALL CHARACTERS/LOCATIONS mentioned in scenes have a corresponding entry in 'turntable'.
"""

# ------------------------------------------------------------------
# JSON í”„ë¡œí•„ í…ìŠ¤íŠ¸ ë³€í™˜ (ê°œì„ ëœ ë²„ì „)
# ------------------------------------------------------------------
def json_profile_to_ultra_detailed_text(profile):
    """JSON í”„ë¡œí•„ì˜ ëª¨ë“  ì¤‘ì²© í•„ë“œë¥¼ ìƒì„¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    parts = []
    
    if not isinstance(profile, dict):
        return ""
    
    # 1. PHYSICAL (Physical Appearance)
    if 'physical' in profile and isinstance(profile['physical'], dict):
        phys = profile['physical']
        phys_desc = []
        if 'age' in phys: phys_desc.append(f"Age: {phys['age']}")
        if 'height_cm' in phys: phys_desc.append(f"Height: {phys['height_cm']}cm")
        if 'body_type' in phys: phys_desc.append(f"Body: {phys['body_type']}")
        if 'skin_tone' in phys: phys_desc.append(f"Skin Tone: {phys['skin_tone']}")
        if 'skin_texture' in phys: phys_desc.append(f"Skin Texture: {phys['skin_texture']}")
        if phys_desc: parts.append("PHYSICAL[" + ", ".join(phys_desc) + "]")
    
    # 2. FACE (Facial Details)
    if 'face' in profile and isinstance(profile['face'], dict):
        face = profile['face']
        face_desc = []
        if 'shape' in face: face_desc.append(f"Face Shape: {face['shape']}")
        
        if 'eyes' in face and isinstance(face['eyes'], dict):
            eyes = face['eyes']
            eye_str = []
            if 'color' in eyes: eye_str.append(f"{eyes['color']}")
            if 'shape' in eyes: eye_str.append(eyes['shape'])
            if 'size' in eyes: eye_str.append(eyes['size'])
            if 'special' in eyes: eye_str.append(eyes['special'])
            face_desc.append(f"Eyes: {' '.join(eye_str)}")
            
        if 'lips' in face and isinstance(face['lips'], dict):
            lips = face['lips']
            lip_str = []
            if 'color' in lips: lip_str.append(lips['color'])
            if 'shape' in lips: lip_str.append(lips['shape'])
            if 'texture' in lips: lip_str.append(lips['texture'])
            face_desc.append(f"Lips: {' '.join(lip_str)}")
            
        if 'nose' in face: face_desc.append(f"Nose: {face['nose']}")
        if 'jawline' in face: face_desc.append(f"Jawline: {face['jawline']}")
        if 'skin_details' in face: face_desc.append(f"Face Details: {face['skin_details']}")
        
        if 'hair' in face: # Handle nested hair in face if structured that way
             if isinstance(face['hair'], dict):
                 h = face['hair']
                 face_desc.append(f"Hair: {h.get('color', '')} {h.get('style', '')}")
        
        if face_desc: parts.append("FACE[" + ", ".join(face_desc) + "]")
    
    # 3. HAIR (Hair Details - Main)
    if 'hair' in profile and isinstance(profile['hair'], dict):
        hair = profile['hair']
        hair_desc = []
        if 'color_primary' in hair: hair_desc.append(f"Color: {hair['color_primary']}")
        if 'color_secondary' in hair: hair_desc.append(f"Highlights: {hair['color_secondary']}")
        if 'length_cm' in hair: hair_desc.append(f"Length: {hair['length_cm']}cm")
        if 'style' in hair: hair_desc.append(f"Style: {hair['style']}")
        if 'texture' in hair: hair_desc.append(f"Texture: {hair['texture']}")
        if hair_desc: parts.append("HAIR[" + ", ".join(hair_desc) + "]")
    
    # 4. CLOTHING (Detailed Outfit)
    if 'clothing' in profile and isinstance(profile['clothing'], dict):
        cloth = profile['clothing']
        outfit_desc = []
        for piece in ['top', 'bottom', 'shoes', 'outerwear']:
            if piece in cloth and isinstance(cloth[piece], dict):
                item = cloth[piece]
                item_details = []
                if 'color' in item: item_details.append(item['color'])
                if 'material' in item: item_details.append(item['material'])
                if 'type' in item: item_details.append(item['type'])
                if 'fit' in item: item_details.append(f"fit: {item['fit']}")
                if 'details' in item: item_details.append(f"detail: {item['details']}")
                if item_details:
                    outfit_desc.append(f"{piece.upper()}: {' '.join(item_details)}")
        if outfit_desc: parts.append("OUTFIT[" + ", ".join(outfit_desc) + "]")
    
    # 5. ACCESSORIES & FEATURES
    if 'accessories' in profile and isinstance(profile['accessories'], list) and profile['accessories']:
        parts.append("ACCESSORIES[" + ", ".join(profile['accessories']) + "]")
    
    if 'distinctive_features' in profile and isinstance(profile['distinctive_features'], list) and profile['distinctive_features']:
        parts.append("FEATURES[" + ", ".join(profile['distinctive_features']) + "]")
        
    # 6. LOCATION / ENVIRONMENT
    if 'location_type' in profile:
        loc_desc = [f"Type: {profile['location_type']}"]
        
        if 'architecture' in profile and isinstance(profile['architecture'], dict):
            arch = profile['architecture']
            if 'style' in arch: loc_desc.append(f"Style: {arch['style']}")
            if 'materials' in arch and isinstance(arch['materials'], list): 
                loc_desc.append(f"Materials: {', '.join(arch['materials'])}")
        
        if 'lighting' in profile and isinstance(profile['lighting'], dict):
            light = profile['lighting']
            light_strs = []
            if 'time' in light: light_strs.append(f"Time: {light['time']}")
            if 'color_temperature' in light: light_strs.append(light['color_temperature'])
            if 'key_color' in light: light_strs.append(f"Key: {light['key_color']}")
            if 'fill_color' in light: light_strs.append(f"Fill: {light['fill_color']}")
            if 'special_effects' in light: light_strs.append(light['special_effects'])
            loc_desc.append(f"LIGHTING: {' '.join(light_strs)}")
            
        if 'weather' in profile and isinstance(profile['weather'], dict):
            w = profile['weather']
            w_strs = []
            if 'condition' in w: w_strs.append(w['condition'])
            if 'humidity_percent' in w: w_strs.append(f"Humidity: {w['humidity_percent']}%")
            loc_desc.append(f"WEATHER: {' '.join(w_strs)}")
            
        if 'color_palette' in profile and isinstance(profile['color_palette'], dict):
            cp = profile['color_palette']
            cp_strs = []
            if 'dominant' in cp: cp_strs.append(f"Dom: {cp['dominant']}")
            if 'secondary' in cp: cp_strs.append(f"Sec: {cp['secondary']}")
            if 'accent' in cp: cp_strs.append(f"Acc: {cp['accent']}")
            loc_desc.append(f"PALETTE: {' '.join(cp_strs)}")
            
        if 'atmosphere' in profile: loc_desc.append(f"Mood: {profile['atmosphere']}")
        parts.append("LOCATION[" + " | ".join(loc_desc) + "]")

    # 7. PROPS / VEHICLES
    if 'make' in profile and 'model' in profile: # Vehicle
        veh_desc = f"VEHICLE[{profile.get('color', '')} {profile.get('make', '')} {profile.get('model', '')}, {profile.get('year', '')}]"
        parts.append(veh_desc)
        
    if 'dimensions' in profile: # Prop
        prop_desc = f"PROP[{profile.get('color', '')} {profile.get('material', '')} {profile.get('name', '')}, {profile.get('finish', '')} finish]"
        parts.append(prop_desc)
    
    return " ".join(parts)

def apply_json_profiles_to_prompt(base_prompt, used_turntables, turntable_data):
    """JSON í”„ë¡œí•„ì„ í”„ë¡¬í”„íŠ¸ì— ê°•ë ¥í•˜ê²Œ ì£¼ì…"""
    if not used_turntables or not turntable_data:
        return base_prompt
    
    character_profiles = []
    location_profiles = []
    object_profiles = []
    
    for tt_ref in used_turntables:
        found = False
        # ìºë¦­í„°
        if 'characters' in turntable_data:
            for item in turntable_data['characters']:
                if item.get('id') == tt_ref:
                    name = item.get('name_en', item.get('name', 'Character'))
                    if 'json_profile' in item:
                        detailed = json_profile_to_ultra_detailed_text(item['json_profile'])
                        if detailed:
                            # ìºë¦­í„° ì´ë¦„ê³¼ ìƒì„¸ ìŠ¤í™ì„ ë¬¶ì–´ì„œ ì „ë‹¬
                            character_profiles.append(f"({name}: {detailed})")
                    found = True
                    break
        if found: continue

        # ì¥ì†Œ
        if 'locations' in turntable_data:
            for item in turntable_data['locations']:
                if item.get('id') == tt_ref:
                    if 'json_profile' in item:
                        detailed = json_profile_to_ultra_detailed_text(item['json_profile'])
                        if detailed:
                            location_profiles.append(detailed)
                    found = True
                    break
        if found: continue
        
        # ì†Œí’ˆ/ì°¨ëŸ‰
        for cat in ['props', 'vehicles']:
            if cat in turntable_data:
                for item in turntable_data[cat]:
                    if item.get('id') == tt_ref:
                         if 'json_profile' in item:
                            detailed = json_profile_to_ultra_detailed_text(item['json_profile'])
                            if detailed:
                                object_profiles.append(detailed)
                         break

    # í”„ë¡¬í”„íŠ¸ ì¡°í•©: ìºë¦­í„° ìŠ¤í™ -> ì¥ì†Œ ìŠ¤í™ -> ì•¡ì…˜(ê¸°ë³¸ í”„ë¡¬í”„íŠ¸)
    final_parts = []
    
    if character_profiles:
        final_parts.append("**CHARACTERS:** " + ", ".join(character_profiles))
    
    if location_profiles:
        final_parts.append("**LOCATION:** " + " | ".join(location_profiles))
        
    if object_profiles:
        final_parts.append("**OBJECTS:** " + ", ".join(object_profiles))
        
    final_parts.append("**SCENE ACTION:** " + base_prompt)
    
    return "\n".join(final_parts)

# ------------------------------------------------------------------
# ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜ë“¤
# ------------------------------------------------------------------
def create_json_export(plan_data):
    return json.dumps(plan_data, ensure_ascii=False, indent=2)

def create_text_export(plan_data):
    """í…ìŠ¤íŠ¸ í˜•ì‹ ë‚´ë³´ë‚´ê¸°"""
    lines = []
    lines.append("=" * 80)
    lines.append("AI MV DIRECTOR PRO - í”„ë¡œì íŠ¸ ê¸°íšì„œ")
    lines.append("=" * 80)
    lines.append(f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    
    lines.append(f"í”„ë¡œì íŠ¸: {plan_data.get('project_title', '')}")
    lines.append(f"Project: {plan_data.get('project_title_en', '')}")
    lines.append(f"ì»¨ì…‰: {plan_data.get('logline', '')}")
    lines.append(f"Concept: {plan_data.get('logline_en', '')}")
    lines.append("")
    
    if 'director_vision' in plan_data:
        lines.append("-" * 40)
        lines.append("DIRECTOR'S VISION")
        lines.append("-" * 40)
        lines.append(plan_data['director_vision'])
        lines.append("")
    
    if 'youtube' in plan_data:
        yt = plan_data['youtube']
        lines.append("-" * 40)
        lines.append("YOUTUBE")
        lines.append("-" * 40)
        lines.append(f"ì œëª©: {yt.get('title', '')}")
        lines.append(f"ì„¤ëª…:\n{yt.get('description', '')}")
        lines.append(f"íƒœê·¸: {yt.get('hashtags', '')}")
        lines.append("")
    
    if 'music' in plan_data:
        music = plan_data['music']
        lines.append("-" * 40)
        lines.append("MUSIC / SUNO AI")
        lines.append("-" * 40)
        lines.append(f"ìŠ¤íƒ€ì¼: {music.get('style', '')}")
        lines.append("")
        lines.append("[STYLE TAGS]")
        lines.append(music.get('style_tags', ''))
        lines.append("")
        lines.append("[VOCAL DIRECTION]")
        lines.append(music.get('vocal_direction', ''))
        lines.append("")
        lines.append("[INSTRUMENTATION]")
        lines.append(music.get('instrumentation', ''))
        lines.append("")
        lines.append("[PRODUCTION]")
        lines.append(music.get('production', ''))
        lines.append("")
        lines.append("[SONG STRUCTURE]")
        lines.append(music.get('song_structure', ''))
        lines.append("")
        lines.append("[COMPLETE LYRICS]")
        lines.append(music.get('lyrics_full', ''))
        lines.append("")
    
    if 'turntable' in plan_data:
        tt = plan_data['turntable']
        lines.append("-" * 40)
        lines.append("TURNTABLE SHEETS")
        lines.append("-" * 40)
        
        for cat in ['characters', 'locations', 'props', 'vehicles']:
            if cat in tt and tt[cat]:
                lines.append(f"\n[{cat.upper()}]")
                for item in tt[cat]:
                    lines.append(f"\n  {item.get('name', '')} ({item.get('id', '')})")
                    if 'views' in item:
                        for view in item['views']:
                            lines.append(f"    - {view.get('view_type', '')}: {view.get('prompt', '')}")
        lines.append("")
    
    if 'scenes' in plan_data:
        lines.append("-" * 40)
        lines.append("STORYBOARD")
        lines.append("-" * 40)
        for scene in plan_data['scenes']:
            lines.append(f"\n[SCENE {scene.get('scene_num', '')}] {scene.get('timecode', '')}")
            lines.append(f"  ì•¡ì…˜: {scene.get('action', '')}")
            if 'camera' in scene and isinstance(scene['camera'], dict):
                cam = scene['camera']
                lines.append(f"  ì¹´ë©”ë¼: {cam.get('shot_type', '')} / {cam.get('movement', '')} / {cam.get('lens', '')}")
            lines.append(f"  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸: {scene.get('image_prompt', '')}")
            lines.append(f"  ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸: {scene.get('video_prompt', '')}")
    
    return "\n".join(lines)

def create_html_export(plan_data):
    """HTML í˜•ì‹ ë‚´ë³´ë‚´ê¸°"""
    html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{plan_data.get('project_title', 'MV Project')}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: 'Pretendard', -apple-system, sans-serif; background: #0a0a0a; color: #fff; line-height: 1.6; }}
        .container {{ max-width: 1200px; margin: 0 auto; padding: 40px 20px; }}
        h1 {{ font-size: 3em; margin-bottom: 10px; background: linear-gradient(135deg, #667eea, #764ba2); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }}
        h2 {{ font-size: 1.8em; margin: 40px 0 20px; padding-bottom: 10px; border-bottom: 2px solid #333; }}
        h3 {{ font-size: 1.3em; margin: 20px 0 10px; color: #667eea; }}
        .section {{ background: #111; border-radius: 12px; padding: 25px; margin: 20px 0; border: 1px solid #222; }}
        .meta {{ color: #888; font-size: 0.9em; margin-bottom: 30px; }}
        .prompt-box {{ background: #1a1a2e; border-left: 4px solid #667eea; padding: 15px; margin: 10px 0; border-radius: 0 8px 8px 0; font-family: monospace; font-size: 0.9em; white-space: pre-wrap; word-break: break-all; }}
        .scene {{ background: #0f0f1a; border-radius: 8px; padding: 20px; margin: 15px 0; border: 1px solid #1a1a2e; }}
        .scene-header {{ display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px; }}
        .scene-num {{ background: linear-gradient(135deg, #667eea, #764ba2); padding: 5px 15px; border-radius: 20px; font-weight: bold; }}
        .timecode {{ color: #888; font-family: monospace; }}
        .tag {{ display: inline-block; background: #222; padding: 4px 12px; border-radius: 15px; margin: 4px; font-size: 0.85em; }}
        .turntable {{ background: #1a1a0a; border: 2px solid #ffd700; border-radius: 12px; padding: 20px; margin: 15px 0; }}
        .copy-btn {{ background: #667eea; color: white; border: none; padding: 8px 16px; border-radius: 5px; cursor: pointer; font-size: 0.85em; }}
        .copy-btn:hover {{ background: #764ba2; }}
        .grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
        pre {{ white-space: pre-wrap; word-wrap: break-word; }}
        .suno-section {{ background: #1a0a1a; border: 1px solid #722ed1; border-radius: 8px; padding: 15px; margin: 10px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¬ {plan_data.get('project_title', '')}</h1>
        <p class="meta">{plan_data.get('project_title_en', '')} | Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}</p>
        
        <div class="section">
            <h2>ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”</h2>
            <p><strong>ì»¨ì…‰:</strong> {plan_data.get('logline', '')}</p>
            <p><strong>Concept:</strong> {plan_data.get('logline_en', '')}</p>
            <p><strong>Director's Vision:</strong> {plan_data.get('director_vision', '')}</p>
        </div>
"""
    
    # YouTube
    if 'youtube' in plan_data:
        yt = plan_data['youtube']
        html += f"""
        <div class="section">
            <h2>ğŸ“º YouTube</h2>
            <h3>ì œëª©</h3>
            <div class="prompt-box">{yt.get('title', '')}</div>
            <h3>ì„¤ëª…</h3>
            <div class="prompt-box">{yt.get('description', '')}</div>
            <h3>í•´ì‹œíƒœê·¸</h3>
            <div class="prompt-box">{yt.get('hashtags', '')}</div>
        </div>
"""
    
    # Music
    if 'music' in plan_data:
        music = plan_data['music']
        html += f"""
        <div class="section">
            <h2>ğŸµ Music / Suno AI</h2>
            <div class="suno-section">
                <h3>Style Tags</h3>
                <div class="prompt-box">{music.get('style_tags', '')}</div>
            </div>
            <div class="suno-section">
                <h3>Vocal Direction</h3>
                <div class="prompt-box">{music.get('vocal_direction', '')}</div>
            </div>
            <div class="suno-section">
                <h3>Instrumentation</h3>
                <div class="prompt-box">{music.get('instrumentation', '')}</div>
            </div>
            <div class="suno-section">
                <h3>Production</h3>
                <div class="prompt-box">{music.get('production', '')}</div>
            </div>
            <div class="suno-section">
                <h3>Song Structure</h3>
                <div class="prompt-box">{music.get('song_structure', '')}</div>
            </div>
            <div class="suno-section">
                <h3>Complete Lyrics</h3>
                <div class="prompt-box">{music.get('lyrics_full', '')}</div>
            </div>
            <div class="suno-section">
                <h3>ğŸ¹ Complete Suno Prompt (Copy All)</h3>
                <div class="prompt-box">{music.get('suno_prompt_combined', '')}</div>
            </div>
        </div>
"""
    
    # Turntable
    if 'turntable' in plan:
        tt = plan_data['turntable']
        html += """
        <div class="section">
            <h2>ğŸ­ Turntable Reference Sheets</h2>
"""
        for cat in ['characters', 'locations', 'props', 'vehicles']:
            if cat in tt and tt[cat]:
                html += f"<h3>{cat.upper()}</h3><div class='grid'>"
                for item in tt[cat]:
                    html += f"""
                    <div class="turntable">
                        <h4>{item.get('name', '')} ({item.get('id', '')})</h4>
"""
                    if 'views' in item:
                        for view in item['views']:
                            html += f"""
                        <p><strong>{view.get('view_type', '')}:</strong></p>
                        <div class="prompt-box">{view.get('prompt', '')}</div>
"""
                    html += "</div>"
                html += "</div>"
        html += "</div>"
    
    # Scenes
    if 'scenes' in plan_data:
        html += """
        <div class="section">
            <h2>ğŸ¬ Storyboard</h2>
"""
        for scene in plan_data['scenes']:
            camera_info = ""
            if 'camera' in scene and isinstance(scene['camera'], dict):
                cam = scene['camera']
                camera_info = f"{cam.get('shot_type', '')} | {cam.get('movement', '')} | {cam.get('lens', '')} | {cam.get('angle', '')}"
            
            html += f"""
            <div class="scene">
                <div class="scene-header">
                    <span class="scene-num">Scene {scene.get('scene_num', '')}</span>
                    <span class="timecode">{scene.get('timecode', '')}</span>
                </div>
                <p><strong>Action:</strong> {scene.get('action', '')}</p>
                <p><strong>Camera:</strong> {camera_info}</p>
                <p><strong>Emotion:</strong> {scene.get('emotion', '')}</p>
                <h4>Image Prompt:</h4>
                <div class="prompt-box">{scene.get('image_prompt', '')}</div>
                <h4>Video Prompt:</h4>
                <div class="prompt-box">{scene.get('video_prompt', '')}</div>
            </div>
"""
        html += "</div>"
    
    html += """
    </div>
    <script>
        document.querySelectorAll('.prompt-box').forEach(box => {{
            box.style.cursor = 'pointer';
            box.title = 'Click to copy';
            box.addEventListener('click', () => {{
                navigator.clipboard.writeText(box.textContent);
                const original = box.style.borderColor;
                box.style.borderColor = '#00ff00';
                setTimeout(() => box.style.borderColor = original, 500);
            }});
        }});
    </script>
</body>
</html>"""
    return html

# ------------------------------------------------------------------
# ì´ë¯¸ì§€ ìƒì„± (Segmind ì¶”ê°€)
# ------------------------------------------------------------------
def generate_image_segmind(prompt, width, height, api_key):
    """Segmind APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìƒì„±"""
    if not api_key:
        return None
    
    # SDXL 1.0 ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸
    url = "https://api.segmind.com/v1/sdxl1.0-txt2img"
    
    payload = {
        "prompt": prompt,
        "negative_prompt": "ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, blurry, bad anatomy, blurred, watermark, grainy, signature, cut off, draft",
        "style": "cinematic",
        "samples": 1,
        "scheduler": "UniPC",
        "num_inference_steps": 25,
        "guidance_scale": 7.5,
        "seed": random.randint(1, 10000000),
        "img_width": width,
        "img_height": height,
        "base64": False
    }
    
    headers = {'x-api-key': api_key}
    
    try:
        response = requests.post(url, json=payload, headers=headers, timeout=60)
        if response.status_code == 200:
            return Image.open(BytesIO(response.content))
    except Exception as e:
        print(f"Segmind Error: {e}")
    return None

def try_generate_image_with_fallback(prompt, width, height, provider, max_retries=3):
    """ì´ë¯¸ì§€ ìƒì„± ì‹œë„ ë° í´ë°± ë¡œì§"""
    enhanced = f"{prompt}, masterpiece, best quality, highly detailed"
    
    # 1. Segmind ìš°ì„  ì‹œë„ (ì„ íƒëœ ê²½ìš°)
    if "Segmind" in provider:
        # ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •í•œ segmind_key ê°€ì ¸ì˜¤ê¸° (ì „ì—­ë³€ìˆ˜ í™œìš©)
        if 'segmind_key' in globals() and segmind_key:
            img = generate_image_segmind(enhanced, width, height, segmind_key)
            if img: return img, "Segmind"
        # í‚¤ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•˜ë©´ Pollinationsë¡œ í´ë°±í•˜ë˜ ë¡œê·¸ ë‚¨ê¹€
    
    # 2. Pollinations (ê¸°ë³¸ ë˜ëŠ” í´ë°±)
    if "Flux" in provider:
        url = f"https://image.pollinations.ai/prompt/{urllib.parse.quote(enhanced)}?width={width}&height={height}&model=flux&nologo=true&seed={random.randint(0,999999)}"
    else: # Turbo or Fallback
        url = f"https://image.pollinations.ai/prompt/{urllib.parse.quote(enhanced)}?width={width}&height={height}&nologo=true&seed={random.randint(0,999999)}"
    
    for attempt in range(max_retries):
        try:
            response = requests.get(url, timeout=90)
            if response.status_code == 200 and len(response.content) > 1000:
                img = Image.open(BytesIO(response.content))
                if img.size[0] > 100:
                    return img, provider
        except Exception as e:
            pass
        if attempt < max_retries - 1:
            time.sleep(2)

    return None, None

def get_preview_size(width, height):
    """í”„ë¦¬ë·°ìš© ì €í™”ì§ˆ ì‚¬ì´ì¦ˆ ê³„ì‚° (ì›ë³¸ì˜ 50% ë˜ëŠ” ìµœëŒ€ 512px)"""
    scale = min(512 / max(width, height), 0.5)
    preview_w = max(256, int(width * scale))
    preview_h = max(256, int(height * scale))
    # 8ì˜ ë°°ìˆ˜ë¡œ ë§ì¶¤ (ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ ìš”êµ¬ì‚¬í•­)
    preview_w = (preview_w // 8) * 8
    preview_h = (preview_h // 8) * 8
    return preview_w, preview_h

def generate_all_preview_images(plan_data, img_width, img_height, provider, use_json=True, max_retries=2):
    """ëª¨ë“  ì”¬ì˜ í”„ë¦¬ë·° ì´ë¯¸ì§€ë¥¼ ìë™ ìƒì„±"""
    if not plan_data:
        return

    scenes = plan_data.get('scenes', [])
    if not scenes:
        return

    # í”„ë¦¬ë·°ìš© ì €í™”ì§ˆ ì‚¬ì´ì¦ˆ
    preview_w, preview_h = get_preview_size(img_width, img_height)

    # ì§„í–‰ ìƒíƒœ í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()

    generated_count = 0
    total_scenes = len(scenes)

    for idx, scene in enumerate(scenes):
        scene_num = scene.get('scene_num', idx + 1)
        status_text.text(f"ğŸ¨ í”„ë¦¬ë·° ì´ë¯¸ì§€ ìƒì„± ì¤‘... ({idx + 1}/{total_scenes}) - Scene {scene_num}")

        # ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        base_prompt = scene.get('image_prompt', '')
        if not base_prompt:
            continue

        # JSON í”„ë¡œí•„ ì ìš©
        if use_json and 'used_turntables' in scene:
            final_prompt = apply_json_profiles_to_prompt(
                base_prompt,
                scene['used_turntables'],
                plan_data.get('turntable', {})
            )
        else:
            final_prompt = base_prompt

        # í”„ë¦¬ë·° ì´ë¯¸ì§€ ìƒì„±
        img, _ = try_generate_image_with_fallback(final_prompt, preview_w, preview_h, provider, max_retries)

        if img:
            if 'generated_images' not in st.session_state:
                st.session_state['generated_images'] = {}
            st.session_state['generated_images'][scene_num] = img
            generated_count += 1

        progress_bar.progress((idx + 1) / total_scenes)
        time.sleep(0.3)  # API ë¶€í•˜ ë°©ì§€

    progress_bar.empty()
    status_text.empty()

    if generated_count > 0:
        st.toast(f"âœ… {generated_count}ê°œ í”„ë¦¬ë·° ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ! ({preview_w}x{preview_h})")

    return generated_count

# ------------------------------------------------------------------
# API ìƒì„±
# ------------------------------------------------------------------
def generate_with_fallback(prompt, api_key, model_name):
    genai.configure(api_key=api_key)
    # ìµœì‹  Gemini API ëª¨ë¸ (2025) - ì•ˆì •ì ì¸ ìˆœì„œë¡œ ë°°ì—´
    models_to_try = [
        model_name,
        "gemini-2.5-flash",      # ìµœì‹  ë¹ ë¥¸ ëª¨ë¸
        "gemini-2.0-flash",      # ì•ˆì •ì ì¸ ëª¨ë¸
        "gemini-1.5-flash",      # ë ˆê±°ì‹œ ë¹ ë¥¸ ëª¨ë¸
        "gemini-1.5-pro",        # ë ˆê±°ì‹œ ê³ ì„±ëŠ¥ ëª¨ë¸
    ]
    # ì¤‘ë³µ ì œê±°
    models_to_try = list(dict.fromkeys(models_to_try))
    last_error = None

    for model in models_to_try:
        try:
            gen_model = genai.GenerativeModel(model)
            response = gen_model.generate_content(prompt, generation_config={"temperature": 0.8, "max_output_tokens": 8192})
            return response.text, model
        except Exception as e:
            last_error = f"{model}: {str(e)}"
            st.toast(f"âš ï¸ {model} ì‹¤íŒ¨, ë‹¤ìŒ ëª¨ë¸ ì‹œë„ ì¤‘...")
            time.sleep(1)
    raise Exception(f"All models failed. Last error: {last_error}")

def generate_plan_auto(topic, api_key, model_name, scene_count, options, genre, visual_style, music_genre, use_json, expert_mode, seconds_per_scene):
    response_text = None
    for attempt in range(3):
        try:
            prompt = get_system_prompt(topic, scene_count, options, genre, visual_style, music_genre, use_json, expert_mode, seconds_per_scene)
            response_text, used_model = generate_with_fallback(prompt, api_key, model_name)

            cleaned = clean_json_text(response_text)
            plan_data = json.loads(cleaned)
            st.toast(f"âœ… ìƒì„± ì™„ë£Œ ({used_model})")
            return plan_data
        except json.JSONDecodeError as e:
            if attempt < 2:
                st.warning(f"JSON íŒŒì‹± ì¬ì‹œë„ ì¤‘... ({attempt+1}/3) - {str(e)[:50]}")
                time.sleep(2)
            else:
                st.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                if response_text:
                    with st.expander("ğŸ” ìƒì„±ëœ ì›ë³¸ ì‘ë‹µ í™•ì¸"):
                        st.code(response_text[:3000] + "..." if len(response_text) > 3000 else response_text)
                return None
        except Exception as e:
            if attempt < 2:
                st.warning(f"ì¬ì‹œë„ ì¤‘... ({attempt+1}/3) - {str(e)[:100]}")
                time.sleep(2)
            else:
                st.error(f"ìƒì„± ì‹¤íŒ¨: {e}")
                return None
    return None

# ------------------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰
# ------------------------------------------------------------------
if submit_btn:
    if not topic:
        st.warning("âš ï¸ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
    else:
        story_opts = {
            'use_arc': use_arc, 'use_trial': use_trial,
            'use_sensory': use_sensory, 'use_dynamic': use_dynamic,
            'use_emotional': use_emotional, 'use_climax': use_climax,
            'use_symbolic': use_symbolic, 'use_twist': use_twist
        }

        if execution_mode == "API ìë™ ì‹¤í–‰":
            if not gemini_key:
                st.warning("âš ï¸ API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤")
            else:
                # ì„¸ì…˜ ì´ˆê¸°í™” (ì´ë¯¸ì§€ ì œì™¸)
                st.session_state['plan_data'] = None
                st.session_state['use_json_profiles'] = use_json_profiles
                st.session_state['expert_mode'] = expert_mode
                st.session_state['image_width'] = image_width
                st.session_state['image_height'] = image_height
                st.session_state['seconds_per_scene'] = seconds_per_scene
                
                with st.spinner("ğŸ¬ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ê¸°íšì•ˆ ìƒì„± ì¤‘... (30ì´ˆ-2ë¶„ ì†Œìš”)"):
                    st.session_state['plan_data'] = generate_plan_auto(
                        topic, gemini_key, gemini_model, scene_count, story_opts,
                        selected_genre, selected_visual, selected_music, 
                        use_json_profiles, expert_mode, seconds_per_scene
                    )
                
                if st.session_state['plan_data']:
                    st.success("âœ… ê¸°íšì•ˆ ìƒì„± ì™„ë£Œ!")

                    # ìë™ ì´ë¯¸ì§€ ìƒì„±ì´ ì¼œì ¸ ìˆìœ¼ë©´ í”„ë¦¬ë·° ì´ë¯¸ì§€ ìƒì„±
                    if auto_generate:
                        st.info("ğŸ¨ ìë™ í”„ë¦¬ë·° ì´ë¯¸ì§€ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                        generate_all_preview_images(
                            st.session_state['plan_data'],
                            image_width, image_height,
                            image_provider,
                            use_json=use_json_profiles,
                            max_retries=2
                        )

                    st.balloons()
                    time.sleep(1)
                    st.rerun()
        else:
            # ìˆ˜ë™ ëª¨ë“œ
            st.session_state['manual_prompt'] = get_system_prompt(
                topic, scene_count, story_opts,
                selected_genre, selected_visual, selected_music,
                use_json_profiles, expert_mode, seconds_per_scene
            )
            st.session_state['show_manual'] = True

# ìˆ˜ë™ ëª¨ë“œ í‘œì‹œ (ìˆ˜ì •ë¨: ê²°ê³¼ ë¶™ì—¬ë„£ê¸° ì°½ ì™¸ë¶€ ë…¸ì¶œ)
if st.session_state.get('show_manual') and 'manual_prompt' in st.session_state:
    st.markdown("---")
    
    # 1. AI í”„ë¡¬í”„íŠ¸ (ì ‘ì„ ìˆ˜ ìˆìŒ)
    with st.expander("ğŸ“‹ ìˆ˜ë™ ëª¨ë“œ - AI í”„ë¡¬í”„íŠ¸ (í´ë¦­í•˜ì—¬ í¼ì¹˜ê¸°)", expanded=False):
        col_guide, col_gemini = st.columns([6, 1])
        with col_guide:
            st.caption("ğŸ‘‡ ì•„ë˜ í”„ë¡¬í”„íŠ¸ì˜ ìš°ì¸¡ ìƒë‹¨ 'ë³µì‚¬(ğŸ“„)' ì•„ì´ì½˜ì„ í´ë¦­í•˜ì—¬ AIì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”.")
        with col_gemini:
            st.link_button("ğŸš€ Gemini", "https://gemini.google.com/app", use_container_width=True)
        
        st.code(st.session_state['manual_prompt'], language="text")
    
    # 2. ê²°ê³¼ ë¶™ì—¬ë„£ê¸° (í•­ìƒ ë³´ì„)
    st.markdown("### ğŸ“¥ ê²°ê³¼ ë¶™ì—¬ë„£ê¸° (JSON)")
    manual_result = st.text_area("AI ì‘ë‹µ JSONì„ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:", height=300, key="manual_json_input")
    
    if st.button("âœ… JSON ì ìš©", type="primary"):
        if manual_result:
            try:
                cleaned = clean_json_text(manual_result)
                st.session_state['plan_data'] = json.loads(cleaned)
                st.session_state['show_manual'] = False
                st.success("âœ… ì ìš© ì™„ë£Œ!")

                # ìë™ ì´ë¯¸ì§€ ìƒì„±ì´ ì¼œì ¸ ìˆìœ¼ë©´ í”„ë¦¬ë·° ì´ë¯¸ì§€ ìƒì„±
                if auto_generate:
                    st.info("ğŸ¨ ìë™ í”„ë¦¬ë·° ì´ë¯¸ì§€ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                    img_w = st.session_state.get('image_width', 1024)
                    img_h = st.session_state.get('image_height', 576)
                    use_json = st.session_state.get('use_json_profiles', True)
                    generate_all_preview_images(
                        st.session_state['plan_data'],
                        img_w, img_h,
                        image_provider,
                        use_json=use_json,
                        max_retries=2
                    )

                st.rerun()
            except json.JSONDecodeError as e:
                st.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")

# ------------------------------------------------------------------
# ê²°ê³¼ í‘œì‹œ
# ------------------------------------------------------------------
if st.session_state.get('plan_data'):
    plan = st.session_state['plan_data']
    use_json = st.session_state.get('use_json_profiles', True)
    img_width = st.session_state.get('image_width', 1024)
    img_height = st.session_state.get('image_height', 576)
    
    st.markdown("---")
    st.header(f"ğŸ¬ {plan.get('project_title', 'Project')}")
    if 'project_title_en' in plan:
        st.caption(plan['project_title_en'])
    
    st.markdown(f"**ì»¨ì…‰:** {plan.get('logline', '')}")
    if 'director_vision' in plan:
        st.info(f"ğŸ¥ **Director's Vision:** {plan['director_vision']}")
    
    # ë‚´ë³´ë‚´ê¸° ë²„íŠ¼ë“¤
    st.markdown("### ğŸ’¾ í”„ë¡œì íŠ¸ ì €ì¥")
    col_save1, col_save2, col_save3, col_save4 = st.columns(4)
    with col_save1:
        st.download_button(
            "ğŸ“„ JSON",
            data=create_json_export(plan),
            file_name=f"{plan.get('project_title', 'project')}.json",
            mime="application/json",
            use_container_width=True
        )
    with col_save2:
        st.download_button(
            "ğŸ“ TXT",
            data=create_text_export(plan),
            file_name=f"{plan.get('project_title', 'project')}.txt",
            mime="text/plain",
            use_container_width=True
        )
    with col_save3:
        st.download_button(
            "ğŸŒ HTML",
            data=create_html_export(plan),
            file_name=f"{plan.get('project_title', 'project')}.html",
            mime="text/html",
            use_container_width=True
        )
    with col_save4:
        # Markdown í˜•ì‹
        md_content = f"# {plan.get('project_title', '')}\n\n{create_text_export(plan)}"
        st.download_button(
            "ğŸ“‹ Markdown",
            data=md_content,
            file_name=f"{plan.get('project_title', 'project')}.md",
            mime="text/markdown",
            use_container_width=True
        )
    
    st.markdown("---")
    
    # YouTube
    if 'youtube' in plan:
        st.markdown("## ğŸ“º YouTube")
        yt = plan['youtube']
        st.text_input("ì œëª©", value=yt.get('title', ''), key="yt_title")
        st.text_area("ì„¤ëª…", value=yt.get('description', ''), height=150, key="yt_desc")
        st.text_input("íƒœê·¸", value=yt.get('hashtags', ''), key="yt_tags")
        if 'thumbnail_concept' in yt:
            st.info(f"ğŸ–¼ï¸ ì¸ë„¤ì¼ ì»¨ì…‰: {yt['thumbnail_concept']}")
    
    st.markdown("---")
    
    # ìŒì•… / Suno (íƒ­ìœ¼ë¡œ ë¶„ë¦¬)
    if 'music' in plan:
        st.markdown("## ğŸµ Music / Suno AI")
        music = plan['music']
        
        suno_tabs = st.tabs(["ğŸ¹ í†µí•© í”„ë¡¬í”„íŠ¸", "ğŸ·ï¸ Style Tags", "ğŸ¤ Vocal", "ğŸ¸ Instruments", "ğŸ›ï¸ Production", "ğŸ“œ Structure", "ğŸ“ Lyrics"])
        
        with suno_tabs[0]:
            st.text_area("Suno ì „ì²´ í”„ë¡¬í”„íŠ¸ (ë³µì‚¬ìš©)", 
                        value=music.get('suno_prompt_combined', music.get('suno_prompt', '')), 
                        height=400, key="suno_all")
        
        with suno_tabs[1]:
            st.text_area("Style Tags", value=music.get('style_tags', ''), height=100, key="suno_style")
        
        with suno_tabs[2]:
            st.text_area("Vocal Direction", value=music.get('vocal_direction', ''), height=100, key="suno_vocal")
        
        with suno_tabs[3]:
            st.text_area("Instrumentation", value=music.get('instrumentation', ''), height=100, key="suno_inst")
        
        with suno_tabs[4]:
            st.text_area("Production", value=music.get('production', ''), height=100, key="suno_prod")
        
        with suno_tabs[5]:
            st.text_area("Song Structure", value=music.get('song_structure', ''), height=300, key="suno_struct")
        
        with suno_tabs[6]:
            st.text_area("Complete Lyrics", value=music.get('lyrics_full', ''), height=300, key="suno_lyrics")
    
    st.markdown("---")
    
    # í„´í…Œì´ë¸”
    if 'turntable' in plan:
        st.markdown("## ğŸ­ Turntable Reference Sheets")
        
        # ì „ì²´ ìƒì„± ë²„íŠ¼
        if st.button("ğŸ¨ ëª¨ë“  í„´í…Œì´ë¸” ì´ë¯¸ì§€ ìƒì„±", use_container_width=True, type="primary", key="gen_all_tt"):
            progress = st.progress(0)
            status = st.empty()
            
            total_views = 0
            for cat in ['characters', 'locations', 'props', 'vehicles']:
                if cat in plan['turntable']:
                    for item in plan['turntable'][cat]:
                        if 'views' in item:
                            total_views += len(item['views'])
            
            current = 0
            for cat in ['characters', 'locations', 'props', 'vehicles']:
                if cat in plan['turntable']:
                    for item in plan['turntable'][cat]:
                        if 'views' in item:
                            for view in item['views']:
                                item_name = item.get('name', '')
                                view_type = view.get('view_type', '')
                                tt_key = f"{cat}_{item.get('id', '')}_{view_type}"
                                
                                status.markdown(f"<div class='status-box'>ìƒì„± ì¤‘: {item_name} - {view_type}</div>", unsafe_allow_html=True)
                                
                                final_prompt = view.get('prompt', '')
                                if use_json and 'json_profile' in item:
                                    detailed = json_profile_to_ultra_detailed_text(item['json_profile'])
                                    if detailed:
                                        final_prompt = f"{detailed}, {final_prompt}"
                                
                                img, _ = try_generate_image_with_fallback(final_prompt, 1024, 1024, image_provider, max_retries)
                                
                                if img:
                                    if 'turntable_images' not in st.session_state:
                                        st.session_state['turntable_images'] = {}
                                    st.session_state['turntable_images'][tt_key] = img
                                
                                current += 1
                                progress.progress(current / total_views)
                                time.sleep(0.5)
            
            status.markdown("<div class='status-box'>âœ… í„´í…Œì´ë¸” ìƒì„± ì™„ë£Œ!</div>", unsafe_allow_html=True)
            st.rerun()
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‘œì‹œ
        for cat in ['characters', 'locations', 'props', 'vehicles']:
            if cat in plan['turntable'] and plan['turntable'][cat]:
                st.markdown(f"### {'ğŸ‘¤' if cat=='characters' else 'ğŸ ' if cat=='locations' else 'ğŸ“¦' if cat=='props' else 'ğŸš—'} {cat.upper()}")
                
                for item in plan['turntable'][cat]:
                    st.markdown(f"<div class='turntable-box'>", unsafe_allow_html=True)
                    st.markdown(f"**{item.get('name', '')}** (ID: {item.get('id', '')})")
                    
                    if 'json_profile' in item:
                        with st.expander("ğŸ“Š JSON í”„ë¡œí•„"):
                            st.json(item['json_profile'])
                    
                    if 'views' in item:
                        cols = st.columns(min(len(item['views']), 4))
                        for idx, view in enumerate(item['views']):
                            with cols[idx % 4]:
                                view_type = view.get('view_type', '')
                                tt_key = f"{cat}_{item.get('id', '')}_{view_type}"
                                
                                st.caption(view_type.upper())
                                
                                if tt_key in st.session_state.get('turntable_images', {}):
                                    st.image(st.session_state['turntable_images'][tt_key], use_container_width=True)
                                else:
                                    if st.button(f"ğŸ“¸", key=f"g_{tt_key}"):
                                        final_prompt = view.get('prompt', '')
                                        if use_json and 'json_profile' in item:
                                            detailed = json_profile_to_ultra_detailed_text(item['json_profile'])
                                            if detailed:
                                                final_prompt = f"{detailed}, {final_prompt}"
                                        
                                        with st.spinner("ìƒì„± ì¤‘..."):
                                            img, _ = try_generate_image_with_fallback(final_prompt, 1024, 1024, image_provider, max_retries)
                                        if img:
                                            if 'turntable_images' not in st.session_state:
                                                st.session_state['turntable_images'] = {}
                                            st.session_state['turntable_images'][tt_key] = img
                                            st.rerun()
                                
                                with st.expander("í”„ë¡¬í”„íŠ¸"):
                                    st.code(view.get('prompt', ''), language=None)
                    
                    st.markdown("</div>", unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ì”¬/ìŠ¤í† ë¦¬ë³´ë“œ
    if 'scenes' in plan:
        st.markdown("## ğŸ¬ Storyboard")
        
        # ì „ì²´ ì”¬ ìƒì„± ë²„íŠ¼
        if st.button("ğŸ¨ ëª¨ë“  ì”¬ ì´ë¯¸ì§€ ìƒì„±", use_container_width=True, type="primary", key="gen_all_scenes"):
            scenes = plan['scenes']
            progress = st.progress(0)
            status = st.empty()
            
            for idx, scene in enumerate(scenes):
                scene_num = scene.get('scene_num', idx+1)
                status.markdown(f"<div class='status-box'>Scene {scene_num} ìƒì„± ì¤‘...</div>", unsafe_allow_html=True)
                
                base = scene.get('image_prompt', '')
                if use_json and 'used_turntables' in scene:
                    final = apply_json_profiles_to_prompt(base, scene['used_turntables'], plan.get('turntable', {}))
                else:
                    final = base
                
                img, _ = try_generate_image_with_fallback(final, img_width, img_height, image_provider, max_retries)
                
                if img:
                    if 'generated_images' not in st.session_state:
                        st.session_state['generated_images'] = {}
                    st.session_state['generated_images'][scene_num] = img
                
                progress.progress((idx + 1) / len(scenes))
                time.sleep(0.5)
            
            status.markdown("<div class='status-box'>âœ… ì”¬ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!</div>", unsafe_allow_html=True)
            st.rerun()
        
        # ê°œë³„ ì”¬ í‘œì‹œ
        for scene in plan.get('scenes', []):
            scene_num = scene.get('scene_num', 0)
            
            st.markdown(f"<div class='scene-box'>", unsafe_allow_html=True)
            
            col1, col2 = st.columns([4, 1])
            with col1:
                st.markdown(f"**Scene {scene_num}** - {scene.get('timecode', '')}")
                if 'act' in scene:
                    st.caption(f"Act {scene['act']} | {scene.get('beat', '')}")
                if 'used_turntables' in scene and scene['used_turntables']:
                    for tt in scene['used_turntables']:
                        st.markdown(f"<span class='turntable-tag'>ğŸ­ {tt}</span>", unsafe_allow_html=True)
            with col2:
                if scene_num in st.session_state.get('generated_images', {}):
                    if st.button("ğŸ”„", key=f"r_s_{scene_num}"):
                        del st.session_state['generated_images'][scene_num]
                        st.rerun()
            
            # ì´ë¯¸ì§€ í‘œì‹œ ë˜ëŠ” ìƒì„± ë²„íŠ¼
            if scene_num in st.session_state.get('generated_images', {}):
                st.image(st.session_state['generated_images'][scene_num], use_container_width=True)
            else:
                if st.button(f"ğŸ“¸ ì´ë¯¸ì§€ ìƒì„±", key=f"g_s_{scene_num}"):
                    base = scene.get('image_prompt', '')
                    if use_json and 'used_turntables' in scene:
                        final = apply_json_profiles_to_prompt(base, scene['used_turntables'], plan.get('turntable', {}))
                    else:
                        final = base
                    
                    with st.spinner("ìƒì„± ì¤‘..."):
                        img, _ = try_generate_image_with_fallback(final, img_width, img_height, image_provider, max_retries)
                    if img:
                        if 'generated_images' not in st.session_state:
                            st.session_state['generated_images'] = {}
                        st.session_state['generated_images'][scene_num] = img
                        st.rerun()
            
            # ì”¬ ì •ë³´
            st.write(f"**ì•¡ì…˜:** {scene.get('action', '')}")
            if 'camera' in scene:
                if isinstance(scene['camera'], dict):
                    cam = scene['camera']
                    st.write(f"**ì¹´ë©”ë¼:** {cam.get('shot_type', '')} | {cam.get('movement', '')} | {cam.get('lens', '')} | {cam.get('angle', '')}")
                else:
                    st.write(f"**ì¹´ë©”ë¼:** {scene['camera']}")
            if 'emotion' in scene:
                st.write(f"**ê°ì •:** {scene['emotion']}")
            
            with st.expander("ğŸ–¼ï¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸"):
                # ì‹¤ì œ ìƒì„±ì— ì‚¬ìš©ë  ìµœì¢… í”„ë¡¬í”„íŠ¸ í‘œì‹œ
                final_debug = scene.get('image_prompt', '')
                if use_json and 'used_turntables' in scene:
                    final_debug = apply_json_profiles_to_prompt(final_debug, scene['used_turntables'], plan.get('turntable', {}))
                st.code(final_debug)
            
            with st.expander("ğŸ¬ ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸ (Runway/Pika/Kling ìš©)"):
                st.code(scene.get('video_prompt', ''))
            
            st.markdown("</div>", unsafe_allow_html=True)

# Footer
st.markdown("---")
st.caption("ğŸ¬ AI MV Director Pro | Powered by Gemini & Segmind & Pollinations")
