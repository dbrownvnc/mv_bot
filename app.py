import streamlit as st
import google.generativeai as genai
import os
import json
import re
import urllib.parse
import time
import random
import requests
from io import BytesIO
from PIL import Image

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI MV Director (Final)", layout="wide")

# --- ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .scene-box {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 20px;
        border-left: 6px solid #FFD700; /* HF Yellow */
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .stButton>button {
        width: 100%;
        border-radius: 8px;
    }
</style>
""", unsafe_allow_html=True)

# --- API í‚¤ ë¡œë“œ (Secrets ìš°ì„ ) ---
def get_api_key(key_name):
    # 1. Streamlit Secrets í™•ì¸
    if key_name in st.secrets:
        return st.secrets[key_name]
    # 2. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    elif os.getenv(key_name):
        return os.getenv(key_name)
    return None

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • (Final)")
    
    # 1. Google Gemini API Key
    gemini_key = get_api_key("GOOGLE_API_KEY")
    if gemini_key:
        st.success("âœ… Gemini Key ì—°ê²°ë¨")
    else:
        gemini_key = st.text_input("Google Gemini API Key", type="password")
    
    st.markdown("---")
    
    # 2. Hugging Face Token
    hf_token = get_api_key("HF_TOKEN")
    if hf_token:
        st.success("âœ… Hugging Face Token ì—°ê²°ë¨")
    else:
        hf_token = st.text_input("Hugging Face Token", type="password", help="Write ê¶Œí•œ í† í° í•„ìš”")
        st.caption("[ğŸ‘‰ í† í° ë°œê¸‰ë°›ê¸°](https://huggingface.co/settings/tokens)")
    
    st.markdown("---")
    
    # 3. ëª¨ë¸ ì„ íƒ
    st.subheader("ğŸ¨ í™”ê°€ ëª¨ë¸ ì„ íƒ")
    hf_model_id = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸ ID",
        [
            "black-forest-labs/FLUX.1-dev",     # 1ìˆœìœ„ (ì¶”ì²œ)
            "black-forest-labs/FLUX.1-schnell", # 2ìˆœìœ„ (ê³ ì†)
            "stabilityai/stable-diffusion-xl-base-1.0", 
        ],
        index=0
    )

    st.markdown("---")
    if st.button("ğŸ—‘ï¸ í”„ë¡œì íŠ¸ ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

# --- ë©”ì¸ íƒ€ì´í‹€ ---
st.title("ğŸ¬ AI MV Director (Final)")
st.subheader("ìŠ¤ë§ˆíŠ¸ ëŒ€ê¸° ê¸°ëŠ¥ & ìë™ ì¬ì‹œë„ íƒ‘ì¬")

topic = st.text_area("ì˜ìƒ ì£¼ì œ ì…ë ¥", height=80, placeholder="ì˜ˆ: 2050ë…„ ì‚¬ì´ë²„í‘í¬ ì„œìš¸, ë¹„ ì˜¤ëŠ” ë°¤, ê³ ë…í•œ í˜•ì‚¬")

# --- Gemini ë¡œì§ (ìŠ¤ë§ˆíŠ¸ ëŒ€ê¸° ê¸°ëŠ¥ ì¶”ê°€) ---

def clean_json_text(text):
    match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
    if match: return match.group(1)
    match = re.search(r"```\s*(.*?)\s*```", text, re.DOTALL)
    if match: return match.group(1)
    return text

def generate_with_fallback(prompt, api_key, start_model="gemini-1.5-flash"):
    genai.configure(api_key=api_key)
    
    # ê²€ì¦ëœ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (2.5 ê°™ì€ ì—†ëŠ” ëª¨ë¸ ì œê±°)
    backups = [
        "gemini-1.5-flash",        # [1ìˆœìœ„] ê°€ì¥ ì•ˆì •ì 
        "gemini-2.0-flash-lite-preview-02-05", 
        "gemini-1.5-flash-8b", 
        "gemini-1.0-pro"
    ]
    
    # ì¤‘ë³µ ì œê±°í•˜ë©° ì²´ì¸ êµ¬ì„±
    fallback_chain = [start_model]
    for b in backups:
        if b != start_model:
            fallback_chain.append(b)
    
    last_error = None
    
    for model_name in fallback_chain:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            time.sleep(1)
            return response.text, model_name 
            
        except Exception as e:
            error_msg = str(e)
            
            # [í•µì‹¬] 429 (ì‚¬ìš©ëŸ‰ ì´ˆê³¼) ì—ëŸ¬ ë°œìƒ ì‹œ ëŒ€ê¸° ë¡œì§
            if "429" in error_msg or "Quota exceeded" in error_msg:
                st.warning(f"âš ï¸ ì‚¬ìš©ëŸ‰ ì´ˆê³¼ ({model_name}). 30ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                
                # 30ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´ í‘œì‹œ
                progress_bar = st.progress(0)
                for i in range(30):
                    time.sleep(1)
                    progress_bar.progress((i + 1) / 30)
                progress_bar.empty()
                
                # ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œë„ (ì¬ê·€ í˜¸ì¶œ ëŒ€ì‹  continueë¡œ ë‹¤ìŒ ëª¨ë¸ ì‹œë„ ìœ ë„)
                st.info("ğŸ”„ ì¬ì‹œë„ ì¤‘...")
                # ì—¬ê¸°ì„œëŠ” ë‹¤ìŒ ëª¨ë¸ë¡œ ë„˜ì–´ê°€ê±°ë‚˜, ë£¨í”„ë¥¼ í•œ ë²ˆ ë” ëŒê²Œ í•  ìˆ˜ ìˆìŒ
                # ê°„ë‹¨í•˜ê²Œ ë‹¤ìŒ ë°±ì—… ëª¨ë¸ë¡œ ë„˜ì–´ê°€ì„œ ì‹œë„
                last_error = e
                continue
                
            else:
                # 429ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ë°”ë¡œ ë‹¤ìŒ ëª¨ë¸ë¡œ
                last_error = e
                time.sleep(0.5)
                continue
                
    raise Exception(f"ëª¨ë“  ëª¨ë¸ ì‹œë„ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì—ëŸ¬: {last_error}")

def generate_plan_gemini(topic, api_key):
    try:
        prompt = f"""
        You are a professional Music Video Director.
        Analyze the following theme: "{topic}"
        Create a detailed plan in JSON format ONLY.
        
        JSON Structure:
        {{
          "project_title": "Creative Title (Korean)",
          "logline": "One sentence concept (Korean)",
          "music": {{
            "style": "Genre and Mood (Korean)",
            "suno_prompt": "English prompt for music AI."
          }},
          "visual_style": {{
            "description": "Visual tone (Korean)",
            "character_prompt": "English description of the main character."
          }},
          "scenes": [
            {{
              "scene_num": 1,
              "timecode": "00:00-00:05",
              "action": "Scene description (Korean)",
              "camera": "Shot type (Korean)",
              "image_prompt": "Highly detailed English prompt for image generation."
            }}
            // Create 4 scenes total
          ]
        }}
        """
        response_text, _ = generate_with_fallback(prompt, api_key, "gemini-1.5-flash")
        return json.loads(clean_json_text(response_text))
    except Exception as e:
        st.error(f"ê¸°íšì•ˆ ì˜¤ë¥˜: {e}")
        return None

# --- HF ì´ë¯¸ì§€ ìƒì„± ---
def generate_image_hf(prompt, token, model_id):
    api_url = f"https://api-inference.huggingface.co/models/{model_id}"
    headers = {"Authorization": f"Bearer {token}"}
    seed = random.randint(0, 999999) 
    payload = {
        "inputs": f"{prompt}, cinematic lighting, 8k, high quality",
        "parameters": {"seed": seed} 
    }

    for attempt in range(5):
        try:
            response = requests.post(api_url, headers=headers, json=payload, timeout=30)
            if response.status_code == 200:
                return Image.open(BytesIO(response.content))
            elif "estimated_time" in response.json():
                wait_time = response.json().get("estimated_time", 10)
                st.toast(f"ğŸ˜´ ëª¨ë¸ ê¹¨ìš°ëŠ” ì¤‘... ({wait_time:.1f}ì´ˆ)")
                time.sleep(wait_time + 1)
                continue
            else:
                # ì—ëŸ¬ì§€ë§Œ 429ì¼ ê²½ìš° ëŒ€ê¸°
                if response.status_code == 429:
                    time.sleep(5) 
                    continue
                break
        except Exception as e:
            time.sleep(1)
    return None

# --- ì‹¤í–‰ ë¡œì§ ---

if 'plan_data' not in st.session_state:
    st.session_state['plan_data'] = None
if 'generated_images' not in st.session_state:
    st.session_state['generated_images'] = {} 

start_btn = st.button("ğŸš€ í”„ë¡œì íŠ¸ ì‹œì‘")

if start_btn:
    if not gemini_key or not topic:
        st.warning("Google API Keyì™€ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not hf_token:
        st.warning("Hugging Face Tokenì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        with st.status("ğŸ“ ê¸°íšì•ˆ ì‘ì„± ì¤‘...", expanded=True) as status:
            st.session_state['generated_images'] = {} 
            st.session_state['plan_data'] = generate_plan_gemini(topic, gemini_key)
            status.update(label="ê¸°íšì•ˆ ì‘ì„± ì™„ë£Œ!", state="complete", expanded=False)

# í™”ë©´ í‘œì‹œ
if st.session_state['plan_data']:
    plan = st.session_state['plan_data']
    
    st.divider()
    st.markdown(f"## ğŸ¥ {plan['project_title']}")
    st.info(f"**ë¡œê·¸ë¼ì¸:** {plan['logline']}")
    
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### ğŸµ Music")
        st.write(plan['music']['style'])
        st.code(plan['music']['suno_prompt'], language="text")
    with c2:
        st.markdown("### ğŸ¨ Visuals")
        st.write(plan['visual_style']['description'])
        st.code(plan['visual_style']['character_prompt'], language="text")
    
    st.markdown("---")
    st.subheader(f"ğŸ–¼ï¸ ë¹„ì£¼ì–¼ ìŠ¤í† ë¦¬ë³´ë“œ (Model: {hf_model_id.split('/')[-1]})")

    for scene in plan['scenes']:
        scene_num = scene['scene_num']
        
        with st.container():
            st.markdown(f"<div class='scene-box'>", unsafe_allow_html=True)
            st.markdown(f"#### ğŸ¬ Scene {scene_num} <span style='font-size:0.8em; color:gray'>({scene['timecode']})</span>", unsafe_allow_html=True)
            
            col_text, col_img = st.columns([1, 1.5])
            
            with col_text:
                st.write(f"**ë‚´ìš©:** {scene['action']}")
                st.write(f"**ì´¬ì˜:** {scene['camera']}")
                with st.expander("í”„ë¡¬í”„íŠ¸ ìƒì„¸"):
                    st.code(scene['image_prompt'], language="text")
            
            with col_img:
                if scene_num in st.session_state['generated_images']:
                    st.image(st.session_state['generated_images'][scene_num], use_container_width=True)
                else:
                    if hf_token:
                        with st.spinner("ğŸ“¸ ì´¬ì˜ ì¤‘..."):
                             full_prompt = f"{plan['visual_style']['character_prompt']}, {scene['image_prompt']}"
                             img_data = generate_image_hf(full_prompt, hf_token, hf_model_id)
                             if img_data:
                                 st.session_state['generated_images'][scene_num] = img_data
                                 st.image(img_data, use_container_width=True)
                             else:
                                 st.error("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
                    else:
                        st.info("í† í° ì…ë ¥ í•„ìš”")

                if st.button(f"ğŸ”„ ë‹¤ì‹œ ê·¸ë¦¬ê¸°", key=f"regen_{scene_num}"):
                     if hf_token:
                        with st.spinner("ğŸ“¸ ì¬ì´¬ì˜ ì¤‘..."):
                            full_prompt = f"{plan['visual_style']['character_prompt']}, {scene['image_prompt']}"
                            img_data = generate_image_hf(full_prompt, hf_token, hf_model_id)
                            if img_data:
                                st.session_state['generated_images'][scene_num] = img_data
                                st.rerun()
            
            st.markdown("</div>", unsafe_allow_html=True)

    if len(st.session_state['generated_images']) == len(plan['scenes']):
        st.success("âœ¨ ìŠ¤í† ë¦¬ë³´ë“œ ì™„ì„±!")
