import streamlit as st
import google.generativeai as genai
import os
import json
import re
import urllib.parse
import time
import random
import requests
from io import BytesIO
from PIL import Image

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="AI MV Director (Process View)", layout="wide")

# --- ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .scene-box {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 20px;
        border-left: 6px solid #4285F4;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .process-log {
        font-family: monospace;
        font-size: 0.9em;
        color: #0066cc;
        background-color: #f0f7ff;
        padding: 10px;
        border-radius: 5px;
        margin-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

# --- API í‚¤ ë¡œë“œ ---
def get_api_key(key_name):
    if key_name in st.secrets:
        return st.secrets[key_name]
    elif os.getenv(key_name):
        return os.getenv(key_name)
    return None

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # Gemini Key
    gemini_key = get_api_key("GOOGLE_API_KEY")
    if gemini_key:
        st.success("âœ… Gemini Key ì—°ê²°ë¨")
    else:
        gemini_key = st.text_input("Google Gemini API Key", type="password")
    
    st.markdown("---")
    
    # ëª¨ë¸ ì„ íƒ (DeBrief ì•±ì˜ ì„±ê³µ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì ìš©)
    st.subheader("ğŸ¤– ë¶„ì„ ëª¨ë¸ (DeBrief Engine)")
    gemini_model = st.selectbox(
        "ê¸°ë³¸ ëª¨ë¸",
        [
            "gemini-2.0-flash-lite-preview-02-05", # DeBrief 1ìˆœìœ„
            "gemini-1.5-flash",        # ì•ˆì •ì„± 1ìœ„
            "gemini-1.5-flash-8b",     # ì´ˆê³ ì†
            "gemini-1.5-pro",
            "gemini-1.0-pro"
        ],
        index=0
    )
    
    st.markdown("---")
    st.subheader("ğŸ¨ ì´ë¯¸ì§€ ëª¨ë¸")
    image_model = st.selectbox("Pollinations ëª¨ë¸", ["flux", "turbo"], index=0) # Flux ê³ í™”ì§ˆ

    if st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

# --- ë©”ì¸ íƒ€ì´í‹€ ---
st.title("ğŸ¬ AI MV Director")
st.caption("DeBrief ì—”ì§„ íƒ‘ì¬ | ì‹¤ì‹œê°„ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œê°í™”")

topic = st.text_area("ì˜ìƒ ì£¼ì œ ì…ë ¥", height=80, placeholder="ì˜ˆ: 2050ë…„ ì‚¬ì´ë²„í‘í¬ ì„œìš¸, ë¹„ ì˜¤ëŠ” ë°¤, ê³ ë…í•œ í˜•ì‚¬")

# ------------------------------------------------------------------
# 1. Gemini ë¡œì§ (DeBrief ì•±ì˜ ìƒì¡´í˜• í´ë°± ë¡œì§ 100% ì´ì‹)
# ------------------------------------------------------------------

def clean_json_text(text):
    match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
    if match: return match.group(1)
    match = re.search(r"```\s*(.*?)\s*```", text, re.DOTALL)
    if match: return match.group(1)
    return text

def generate_with_fallback(prompt, api_key, start_model):
    genai.configure(api_key=api_key)
    
    # DeBrief ì•±ì˜ í•µì‹¬: ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ëª¨ë¸ë¡œ ë¬´ì¡°ê±´ ë„˜ì–´ê°€ëŠ” ë¦¬ìŠ¤íŠ¸
    # start_modelì„ ê°€ì¥ ì•ì— ë‘ê³ , ë‚˜ë¨¸ì§€ë¥¼ ë’¤ì— ë¶™ì„
    backup_models = [
        "gemini-2.0-flash-lite-preview-02-05",
        "gemini-1.5-flash",
        "gemini-1.5-flash-8b",
        "gemini-1.5-pro",
        "gemini-1.0-pro"
    ]
    
    # ì¤‘ë³µ ì œê±° ë° ì²´ì¸ ìƒì„±
    fallback_chain = [start_model] + [m for m in backup_models if m != start_model]
    
    last_error = None
    log_placeholder = st.empty() # ì§„í–‰ ìƒí™© í‘œì‹œìš©
    
    for model_name in fallback_chain:
        try:
            log_placeholder.markdown(f"<div class='process-log'>ğŸ”„ {model_name} ëª¨ë¸ë¡œ ìƒê° ì¤‘...</div>", unsafe_allow_html=True)
            
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            
            time.sleep(1) # ì•ˆì •ì„± ëŒ€ê¸°
            log_placeholder.empty() # ì„±ê³µí•˜ë©´ ë¡œê·¸ ì§€ì›€
            return response.text, model_name 
            
        except Exception as e:
            last_error = e
            # ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ì°ê³  ë‹¤ìŒìœ¼ë¡œ
            # st.toast(f"âš ï¸ {model_name} ì‹¤íŒ¨ -> ë‹¤ìŒ ëª¨ë¸ ì‹œë„") 
            time.sleep(0.5)
            continue
            
    raise Exception(f"All models failed. Last Error: {last_error}")

# ------------------------------------------------------------------
# 2. ì´ë¯¸ì§€ ìƒì„± ë¡œì§ (íŒŒì´ì¬ ë‚´ë¶€ ë‹¤ìš´ë¡œë“œ -> ë¸Œë¼ìš°ì € ì°¨ë‹¨ í•´ê²°)
# ------------------------------------------------------------------

def fetch_image_server_side(prompt, model="flux"):
    """
    ë¸Œë¼ìš°ì €ê°€ ì•„ë‹Œ ì„œë²„(Python)ê°€ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë°›ì•„ì˜µë‹ˆë‹¤.
    ì´ ë°©ì‹ì€ í•œ ì¥ë§Œ ë‚˜ì˜¤ê³  ë©ˆì¶”ëŠ” ë¬¸ì œë¥¼ 100% í•´ê²°í•©ë‹ˆë‹¤.
    """
    safe_prompt = urllib.parse.quote(prompt[:400])
    seed = random.randint(0, 999999)
    url = f"https://image.pollinations.ai/prompt/{safe_prompt}?width=1024&height=576&model={model}&nologo=true&seed={seed}&enhance=false"
    
    try:
        response = requests.get(url, timeout=20)
        if response.status_code == 200:
            return Image.open(BytesIO(response.content))
    except Exception as e:
        print(f"Image Error: {e}")
    return None

# ------------------------------------------------------------------
# 3. ì‹¤í–‰ ë¡œì§ (ê³¼ì •ì„ ìˆœì„œëŒ€ë¡œ ë³´ì—¬ì£¼ê¸°)
# ------------------------------------------------------------------

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'plan_data' not in st.session_state:
    st.session_state['plan_data'] = None
if 'generated_images' not in st.session_state:
    st.session_state['generated_images'] = {} # {scene_num: ImageObject}

start_btn = st.button("ğŸš€ í”„ë¡œì íŠ¸ ì‹œì‘")

if start_btn:
    if not gemini_key or not topic:
        st.warning("API Keyì™€ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # [ë‹¨ê³„ 1] ê¸°íšì•ˆ ìƒì„±
        st.session_state['generated_images'] = {} # ì´ë¯¸ì§€ ì´ˆê¸°í™”
        st.session_state['plan_data'] = None
        
        with st.status("ğŸ“ ê¸°íšì•ˆ ì‘ì„± ì¤‘...", expanded=True) as status:
            prompt = f"""
            You are a professional Music Video Director.
            Analyze the following theme: "{topic}"
            Create a detailed plan in JSON format ONLY.
            
            JSON Structure:
            {{
              "project_title": "Creative Title (Korean)",
              "logline": "One sentence concept (Korean)",
              "music": {{
                "style": "Genre and Mood (Korean)",
                "suno_prompt": "English prompt for music AI."
              }},
              "visual_style": {{
                "description": "Visual tone (Korean)",
                "character_prompt": "English description of the main character."
              }},
              "scenes": [
                {{
                  "scene_num": 1,
                  "timecode": "00:00-00:05",
                  "action": "Scene description (Korean)",
                  "camera": "Shot type (Korean)",
                  "image_prompt": "Highly detailed English prompt for image generation."
                }}
                // Create 4 scenes total
              ]
            }}
            """
            
            try:
                # Gemini í˜¸ì¶œ
                raw_text, used_model = generate_with_fallback(prompt, gemini_key, gemini_model)
                st.session_state['plan_data'] = json.loads(clean_json_text(raw_text))
                status.update(label=f"ê¸°íš ì™„ë£Œ! (ëª¨ë¸: {used_model})", state="complete", expanded=False)
                
            except Exception as e:
                st.error(f"ê¸°íšì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")

# [ë‹¨ê³„ 2] ê¸°íšì•ˆì´ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ ë¨¼ì € í‘œì‹œ
if st.session_state['plan_data']:
    plan = st.session_state['plan_data']
    
    st.divider()
    st.markdown(f"## ğŸ¥ {plan['project_title']}")
    st.info(f"**ë¡œê·¸ë¼ì¸:** {plan['logline']}")
    
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### ğŸµ Music")
        st.write(plan['music']['style'])
        st.code(plan['music']['suno_prompt'], language="text")
    with c2:
        st.markdown("### ğŸ¨ Visuals")
        st.write(plan['visual_style']['description'])
        st.code(plan['visual_style']['character_prompt'], language="text")
    
    st.markdown("---")
    st.subheader("ğŸ–¼ï¸ ë¹„ì£¼ì–¼ ìŠ¤í† ë¦¬ë³´ë“œ ì œì‘")

    # [ë‹¨ê³„ 3] ì”¬ë³„ ìˆœì°¨ì  ìƒì„± ë° í‘œì‹œ (Real-time Generation)
    # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ì”¬ì´ ìˆë‹¤ë©´, ì—¬ê¸°ì„œ ì¦‰ì‹œ ìƒì„±í•´ì„œ ë³´ì—¬ì¤Œ
    
    for scene in plan['scenes']:
        scene_num = scene['scene_num']
        
        # UI í‹€ ì¡ê¸°
        with st.container():
            st.markdown(f"<div class='scene-box'>", unsafe_allow_html=True)
            st.markdown(f"#### ğŸ¬ Scene {scene_num} <span style='font-size:0.8em; color:gray'>({scene['timecode']})</span>", unsafe_allow_html=True)
            
            col_text, col_img = st.columns([1, 1.5])
            
            with col_text:
                st.write(f"**ë‚´ìš©:** {scene['action']}")
                st.write(f"**ì´¬ì˜:** {scene['camera']}")
                with st.expander("í”„ë¡¬í”„íŠ¸ ìƒì„¸"):
                    st.code(scene['image_prompt'], language="text")
            
            with col_img:
                # 1. ì´ë¯¸ ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë³´ì—¬ì¤Œ
                if scene_num in st.session_state['generated_images']:
                    st.image(st.session_state['generated_images'][scene_num], use_container_width=True)
                    st.success("âœ… ìƒì„± ì™„ë£Œ")
                
                # 2. ì—†ìœ¼ë©´ 'ì§€ê¸ˆ' ìƒì„± (ì‹¤ì‹œê°„ í”„ë¡œì„¸ìŠ¤ ì‹œê°í™”)
                else:
                    # ë¹ˆ ê³µê°„ í™•ë³´
                    img_placeholder = st.empty()
                    status_placeholder = st.empty()
                    
                    status_placeholder.info(f"ğŸ“¸ Scene {scene_num} ì´¬ì˜ ì¤‘... (AIê°€ ê·¸ë¦¬ëŠ” ì¤‘)")
                    
                    # í”„ë¡¬í”„íŠ¸ ì¡°í•©
                    full_prompt = f"{plan['visual_style']['character_prompt']}, {scene['image_prompt']}"
                    
                    # ì„œë²„ ì‚¬ì´ë“œ ë‹¤ìš´ë¡œë“œ (ì•ˆì •ì„± í•µì‹¬)
                    img_data = fetch_image_server_side(full_prompt, image_model)
                    
                    if img_data:
                        # ì„¸ì…˜ì— ì €ì¥
                        st.session_state['generated_images'][scene_num] = img_data
                        # í™”ë©´ì— í‘œì‹œ
                        status_placeholder.empty()
                        img_placeholder.image(img_data, use_container_width=True)
                        # ë‹¤ìŒ ì”¬ ìƒì„±ì„ ìœ„í•´ ì•½ê°„ì˜ í…€ì„ ë‘ê³  Rerun (ìˆœì°¨ì  ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼)
                        time.sleep(0.5) 
                        st.rerun()
                    else:
                        status_placeholder.error("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")

            st.markdown("</div>", unsafe_allow_html=True)

    # ëª¨ë“  ì”¬ ìƒì„± ì™„ë£Œ ì‹œ
    if len(st.session_state['generated_images']) == len(plan['scenes']):
        st.success("âœ¨ ëª¨ë“  ì´¬ì˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (í”„ë¡œì íŠ¸ ì™„ì„±)")
